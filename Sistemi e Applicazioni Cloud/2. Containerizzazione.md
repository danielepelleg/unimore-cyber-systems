- [Containerizzazione](#containerizzazione)
  - [Evoluzione Storica](#evoluzione-storica)
  - [DevOps](#devops)
  - [Benefici della Containerizzazione](#benefici-della-containerizzazione)
  - [Tecnologie](#tecnologie)
    - [Docker](#docker)
      - [Container File-System](#container-file-system)
      - [Volumi](#volumi)
      - [Dockerfile](#dockerfile)
      - [Orchestrazione](#orchestrazione)
        - [Docker-Compose](#docker-compose)
        - [Docker Swarm](#docker-swarm)
        - [Kubernetes](#kubernetes)

# Containerizzazione

La **containerizzazione** è una *tecnologia* utilizzata per raggruppare tutti i file necessari a un'applicazione in un ***ambiente software isolato*** (*container*). Un container ha ***dimensioni standard*** e rende più facili la *gestione del deployment e dell'aggiornamento*. 

Si può pensare ai container ***come a degli eseguibili linkati staticamente***. Quando si parla di oggetti con cui si ha a che fare nel software si fa riferimento ai processi, alla parte statica del codice (*programmi*, *librerie*, *linking*) e ai *pacchetti software*. Il programma non è sempre solo il codice che scriviamo: vengono utilizzate anche delle ***librerie**, che consistono in collezioni di funzioni standard* (per *allocare la memoria*, *aprire file*). I nostri programmi utilizzano queste librerie durante la ***fase di linking***, che può essere *statico* o *dinamico*. 

- Nel **linking statico** il **linker** prende in carico i *file objects `.o`* e le *librerie* `.a` creando un eseguibile che ha all'interno tutti i file e le librerie di cui ha bisogno. Il codice a questo punto non ha bisogno di *nessun altro codice esterno per funzionare*, e si interfaccia al massimo con il *kernel* mediante delle *system call*. Per *aggiornare la libreria* è necessario *ricompilare*. 
- Nel **linking dinamico** l'operazione avviene in *due step*. Si ha sempre la fase di linking, ma stavolta i *files* `.a` ***non sono l'intera libreria***, ma degli ***stubs*** (*lista di funzioni e poco codice di inizializzazione*). All'interno del codice viene inserito un elemento `ld.so` che corrisponde al ***linker dinamico***. Nel momento in cui il codice viene eseguito, `ld.so` carica i *files* `.so` in memoria e le *stub vengono sostituite dal codice `.so` aggiunto*, facendo in modo che le *librerie vengano linkate solo nel momento di bisogno*.

I **pacchetti software** contengono *codice e dipendenze*, e possono causare problemi dovuti a quest'ultime: un aggiornamento può rompere qualcosa, pertanto si può dire che abbiano dei ***bisogni simili ai container***: c'è bisogno di un *meccanismo di pacchettizzazione del software auto-contenuto* (file, librerie, configurazioni), garantendo la *coesistenza di setup diversi*. C'è bisogno di qualcosa di ***spedibile e installabile***.

Con la **containerizzazione** l'astrazione si sposta a ***livello di sistema operativo***, che viene condiviso dai container. Rispetto a una VM richiede un ***minore utilizzo delle risorse*** e ***meno overhead***, nonché un ***minor tempo di avvio***.

## Evoluzione Storica

Il **concetto di container** viene introdotto verso la *fine degli anni '70*, più precisamente nella *Unix V7* del *'79* con il *comando* `chroot`, che ***cambia la directory di riferimento per i processi*** (e i loro *figli*) ***in esecuzione corrente***. Con il comando `chroot` si ha il ***primo esempio di container isolato***, che ***crea un file system isolato per un gruppo di processi***. Questo primo approccio tuttavia ***non offre garanzie in termini di sicurezza***, in quanto ***può essere evaso facilmente*** (`chroot` *viene sovrascritto quando viene lanciato all'interno di un altro* `chroot`). Negli *anni 2000* vengono introdotti i ***sistemi jail***, che offrono un **isolamento più spinto**: si tratta di *sistemi isolati* che possono ***ospitare servizi e configurazioni di rete diversi*** tra loro. In generale, l'evoluzione storica della containerizzazione è simile a quella della virtualizzazione: entrambi hanno un primo interesse attorno agli *anni '70*, che si smorza e viene ripreso qualche anno dopo. 

## DevOps

Il termine fa riferimento ai due mondi di **sviluppo** e **operations** (in informatica inteso come *messa in produzione* o *deployment*). I due erano inizialmente ***due mondi separati***, e ciò comportava un significativo ***rallentamento del ciclo di sviluppo*** e ***problemi di collaborazione tra i team lavorativi***. Per superare i limiti di questo modello, viene utilizzato un **approccio agile**, che permette uno ***sviluppo più veloce*** dove in ogni *release il software presente **poche feature in più** ma **testate*** e anche il ***tempo** tra una **release** e l'altra è **minore***. Le caratteristiche di uno sviluppo di questo tipo, dove la parte di sviluppo e quella di operations sono strettamente collegate, sono le seguenti:

- **Continuous Integration + Continuous Delivery**: si utilizza una ***repository per il codice*** e ad *ogni commit viene testato tutto*.
- **Utilizzo di Microservizi**: divisione di un'applicazione complessa in più *servizi indipendenti*, ciascuno dei quali usa un'API e che *incrementano la scalabilità del sistema*: se c'è bisogno di apportare una modifica è sufficiente lavorare su un singolo servizio.
- **Infrastructure as a Code**: il ***deployment*** può essere definito in *appositi **file di configurazione*** (*numero di repliche*). Permette di *replicare i problemi in caso di bisogno*.
- **Monitoring and Logging**: per avere un idea di cosa sta funzionando e tenere sotto controllo eventuali ***colli di bottiglia***.
- **Comunicazione e Collaborazione**: vengono definiti ***diversi ruoli*** per il ***team di sviluppo*** coordinato da un ***product owner***.

## Benefici della Containerizzazione

Se l'adozione di un *approccio DevOps* viene *semplifica lo sviluppo*, la *Containerizzazione* *semplifica il deployment*. L'Adozione di questa tecnologia comporta diversi vantaggi:

- **Portabilità**: un sistema definito bene *può essere **eseguito su diversi sistemi*** e può lavorare con *backend di **container differenti*** come *Docker, Kubernetes*.
- **Agilità**: data dal poter utilizzare ***immagini di partenza già esistenti*** (es. *sistema linux + apache*)
- **Fault Isolation**: le ***failures*** sono ***limitate a un singolo container***, se c'è un problema questo si trova su un servizio in esecuzione all'interno di un container. La memoria all'interno di un container viene limitata (grazie ai *cgroups*).
- **Efficienza**: data dalla loro ***velocità***, avendo meno componenti da virtualizzare richiedono ***meno overhead***.
- **Facilità di Gestione**: l'***orchestrazione dei container è semplice grazie al software***, che permette una ***gestione automatica*** del container sotto diversi aspetti: *installazione*, *scalabilità*, *avvio e spegnimento*.
- **Sicurezza**: la ***diffusione di codice malevolo*** è quasi ***impossibile tra container differenti***.

## Tecnologie

Il meccanismo di interazione con i container si basa su un ***approccio client-server***: sul sistema sono presenti dei ***daemon*** che ***erogano una serie di servizi*** (*gestione dei container, delle immagini*) e il ***client invoca questi servizi***. Alcuni elementi importanti sono:

- **Gestione del Container  &rarr; *Containerd***: che permette di *eseguire i container*, *gestire le immagini*, *fare un push/pull delle immagini dalle repository in rete*. *Containerd* mette a disposizione le sue ***funzioni*** attraverso delle ***API***, per questo oltre che dall'*ecosistema Docker* viene utilizzato anche da altri *tool* come *Kubernetes*.
- **Container Engine &rarr; Docker**: utilizzato per la ***gestione di immagini e container***
- **Gestione Dati** &rarr; **file-system**
- **Orchestrazione**: ***gestione di più container***. Vengono utilizzati *diversi tool* come *docker-compose*, *docker-swarm* e *kubernetes*.

### Docker

Docker è un **container engine** utilizzato per *costruire immagini*, *gestire immagini* ed *eseguire applicazioni all'interno di container*. Le **immagini** consistono in un ***set di istruzioni per creare un container***. Il **container** rappresenta l'***istanza eseguibile di un'immagine*** ed è a tutti gli effetti un ***oggetto con uno stato*** (può essere in *esecuzione*, in *pausa*). Il *client* interagisce attraverso delle ***REST API*** con il *docker daemon*, che si può interfacciare con il ***Registry*** (*repository di immagini*).

#### Container File-System

L'idea è quella di avere un'***immagine costituita da diversi layers readonly***. Ogni ***aggiunta all'immagine*** di partenza costituisce un ***nuovo layer***, e il **file system** è la ***somma che si apporta di layer in layer***. Solo l'***ultimo layer*** che si apporta all'immagine è ***scrivibile***. L'**immagine** utilizzata per la creazione del container consiste nell'***unione dei layer sottostanti***.

#### Volumi

Un **volume** è un ***file-system montabile all'interno di un container***. Viene normalmente utilizzato come *storage per i dati rilevanti* (*strutture dati del DB*, *risorse WEB*). Rappresenta un modo per ***avere dei dati persistenti*** all'interno dei container: una volta rimosso un container, ***il volume rimane***.

#### Dockerfile

Un dockerfile è un ***file di testo*** contenente la ***descrizione di un container***. In un dockerfile viene definita l'***immagine da utilizzare***, la ***build***, e il ***comando da eseguire all'avvio del container***. Con questo file è inoltre possibile ***automatizzare delle operationi*** (*esecuzione di comandi docker*). I principali comandi sono:

- `FROM <image>[tag]` : utilizzato specificare l'***immagine di partenza***. Nel *tag* viene specificata la *versione dell'immagine* (default `:latest`)
- `COPY <SRC> <DST>` : utilizzata per ***copiare dei file in un'immagine***, in alternativa può essere utilizzato anche il comando `ADD`
- `ENV` : utilizzato per ***definire le variabili d'ambiente*** utilizzate *in fase di build* o a *runtime*
- `RUN` : per ***eseguire un comando durante la build***
- `VOLUME` : per ***specificare un volume montabile***
- `USER` : per ***specificare l'utente con cui vengono lanciati i programmi***
- `WORKDIR`: usato per ***specificare la directory di lavoro***
- `EXPOSE`: utilizzato per ***specificare le porte utilizzate dal container***
- `CMD`: ***comando da eseguire all'avvio del container***

#### Orchestrazione

In uno scenario normale, ad ***ogni servizio*** offerto da un'applicazione è associato ***un container*** (e quindi un *Dockerfile*). Questi container hanno spesso *bisogno di comunicare tra loro*, per questo possono essere utilizzati *diversi tool*, a seconda che questi servizi debbano essere deployati sullo stesso host (*single host*), o su diversi host (*multiple host*).

##### Docker-Compose

Quando i servizi devono essere deployati sullo stesso host è possibile utilizzare ***Docker-compose***, un **tool** per la ***gestione di applicazioni multi-container***. Poiché questi container hanno bisogno di *interagire tra loro*, docker-compose utilizza uno **script** (scritto sotto forma di *dichiarazioni* in ***linguaggio YAML***) dove specifica la ***definizione di questi servizi e dei comportamenti attesi***. 

##### Docker Swarm

Questo tool viene normalmente utilizzato per la ***gestione di cluster***. Ciascun host deve avere installato il *proprio container engine*. Attraverso docker swarm è possibile descrivere il ***deployment***, le ***interazioni*** e le ***dipendenze*** dei containers. Altre caratteristiche di docker swarm sono:

- **Scalabilità**: per ogni servizio è possibile ***specificare un livello di replicazione***, ed è possibile **automatizzare lo scaling**, facendo in modo che ***se lo stato del sistema è diverso da quello desiderato*** allora *vengano prese determinate decisioni*. 
- **Bilanciamento del Carico**: il tool permette di ***specificare come i containers sono distribuiti sui nodi***. 
- **Sicurezza**: le ***comunicazioni tra i nodi sono cifrate*** e inoltre è presente il supporto alle ***Certification Autorities** locali o esterne* che permettono ai nodi di identificarsi.
- **Gestione degli Aggiornamenti**: gli aggiornamenti possono essere ***pianificati sui nodi*** per ***evitare picchi di traffico*** e *distribuendo il carico*

Con il termine **swarm** si fa riferimento a ***più docker host***. Ciascun nodo (*host*) può essere un ***manager***, un ***worker***, o ***sia manager che worker***. Il **manager** è un nodo che ha il compito di ***distribuire i task*** ai nodi ***worker***. Un **task** è un ***insieme di comandi** da **eseguire all'interno di un container***.

##### Kubernetes

Kubernetes viene utilizzato *come docker swarm* in *scenari multi-host*. Si tratta di un ***sistema più ricco e complesso di docker-swarm***, con *caratteristiche simili*. Quelli che prima venivano chiamati *task* ora prendono il nome di ***pods*** e se ne occupa lo ***scheduler*** in termini di *bin packing*, *bilanciamento* e *ridondanza*. Il pod viene normalmente assegnato a *un solo container* (*single container pod*), ma può essere *distribuito su più container* (*multiple container pod*).



