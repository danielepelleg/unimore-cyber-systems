- [Serverless](#serverless)
  - [Principi di FaaS](#principi-di-faas)
    - [Limiti](#limiti)
    - [Casi d'Uso](#casi-duso)

# Serverless

Il termine fa riferimento a un ***approccio per lo sviluppo e il deployment di applicazioni cloud*** basato su un ***modello PasS***, dove l'infrastruttura (*piattaforme hardware e software*) viene ***gestita dal provider***. L'utilizzo di un modello di business di questo tipo comporta un ***grande taglio dei costi***, in quanto non si pagano le macchine ma ***le invocazioni ai servizi***.

**Differenze con IaaS**:

|                           **IaaS**                           |                           **PaaS**                           |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| L'utente ha un ***controllo completo dell'infrastruttura*** (numero di macchine, comunicazione, *load balancing*) | L'utente non si preoccupa su quante istanze girano le cose. Lo ***scaling è automatico***. |
| I **costi** si basano sulla ***capacità allocata***, *non sull'utilizzo effettivo* |     I **costi** si basano sull'***utilizzo effettivo***      |
| Attività di ***monitoraggio e sicurezza*** gestiti dall'***utente*** | Attività di ***monitoraggio e sicurezza*** gestiti dal ***provider*** |

I **servizi serverless** possono essere di due tipi:

- **Backend-as-a-Service (BaaS)**: rendono disponibili dei ***servizi*** ad ***altre applicazioni*** attraverso delle ***API*** (possono essere *servizi di Database* come *Firestore o Firebase*).
- **Function-as-a-Service (FaaS)**: si può definire un ***caso particolare dell'approccio serverless***, e consiste nel rendere disponibile un ***software*** attraverso delle ***funzioni***, con un ***modello di costo basato sul numero di invocazioni e sulla capacità allocata***.

## Principi di FaaS

La **prima evoluzione** di questo modello la si ha come conseguenza diretta dei ***limiti del modello IaaS***: una granularità di gestione a livello di *VM* è troppo grande. C'è bisogno di una granularità più fine che ***limiti il consumo delle risorse quando non se ne ha bisogno***, per questo l'attenzione si sposta sull'utilizzo dei **container** e dei **microservizi**. Il servizio di un applicazione viene messo in un container che presenta ***solo ciò che serve alla funzione***. Un **elemento** di questo tipo è ***indipendente***, e in quanto tale può ***scalare in modo indipendente***. Con la *divisione di un applicazione monolitica* in *microservizi* e poi in ***servizi*** ciascuno con ***cicli di vita diversi***, non si ha più una visione a livello di *web application*, ma a livello di ***singola funzione da chiamare*** (*API*), evitando problemi di gestione dello stato. La divisione in funzioni permette di ***non avere più niente di condiviso tra le istanze di una singola sessione***. Elementi di questo tipo risultano ***facilmente scalabili***, e ***adattabili alle variazioni di carico***.

L'utilizzo dei **container** inoltre rende questi servizi molto *elastici* in termini di *tempistiche*. Un servizio può essere ***avviato in poco tempo*** e le ***istanze possono essere terminate dal cloud provider*** in caso di inutilizzo (attraverso un *timeout*).  Il **modello di costo** si basa sulla ***quantità di risorse utilizzate in un determinato tempo*** e sul ***numero di invocazioni***. Molti servizi cloud mettono a disposizione dei ***piani free tier*** che comprendono *un certo numero di invocazioni gratuito* (utile per *start-up* nelle fasi iniziali che non conoscono il numero di clienti). Con un modello FaaS ***non c'è più bisogno di preccuparsi degli aspetti server***. 

### Limiti

- **PERFORMANCE**: I Server su cui girano i servizi hanno un ***tempo di avvio***. Poiché alcuni servizi a volte possono dare problemi (devono essere *riavviati*, possono essere *lenti*), il modello è sconsigliato per essere utilizzato nei sistemi sensibili alla latenza (*mercati finanziari*).
- **RISORSE LIMITATE**: il ***limite sull'utilizzo delle risorse*** viene ***imposto dal Provider***, è necessario fare un *analisi del carico atteso a lungo termine* per capire *la capacità computazionale di cui si ha bisogno*.
- **MENO CONTROLLO**: ***l'infrastruttura***, essendo a carico del provider, ***non può essere più controllata dall'utente***
- **MONITORAGGIO**: per il ***sistema di monitoring*** è necessario *affidarsi a ciò che viene offerto dal Provider*, e ciò può rendere ***difficile riprodurre i problemi***.
- **SICUREZZA**: i cloud sono sistemi sicuri, ma *non invincibili*, se viene trovata una vulnerabilità in un cloud molti sistemi sono a rischio

### Casi d'Uso

In generale, un **approccio serverless** risulta utile in tutti quei sistemi che hanno bisogno di ***gestire la scalabilità automaticamente***. Nei sistemi che presentano un *traffico irregolare* e sono soggetti a un'***elevata variazione di carico***. Oltre a questi, anche gli **scenari IoT** si prestano bene al serverless, in quanto presentano ***diversi dispositivi da gestire***, ciascuno soggetto a ***esigenze diverse***, che possono comportare dei ***problemi di scalabilità***.