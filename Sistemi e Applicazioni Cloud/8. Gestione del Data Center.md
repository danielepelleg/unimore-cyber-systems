- [Gestione del Data Center](#gestione-del-data-center)
  - [Metriche di Performance](#metriche-di-performance)
    - [Consumo Energetico](#consumo-energetico)
    - [Service Level Agreement (SLA)](#service-level-agreement-sla)
    - [Utilizzo delle Risorse](#utilizzo-delle-risorse)
  - [Modelli di Performance](#modelli-di-performance)
    - [Modello Energetico](#modello-energetico)
    - [Modelli Basati sul Tempo di Risposta](#modelli-basati-sul-tempo-di-risposta)
      - [Notazione dei Sistemi a Coda](#notazione-dei-sistemi-a-coda)
      - [M/M/1](#mm1)
      - [M/G/1](#mg1)
      - [G/G/N](#ggn)
    - [Modelli Basati sull'Affidabilità o Disponibilità](#modelli-basati-sullaffidabilità-o-disponibilità)
    - [Modelli Economici](#modelli-economici)
  - [Variabili Decisionali](#variabili-decisionali)
    - [Posizionamento delle VM](#posizionamento-delle-vm)
    - [Migrazione delle VM](#migrazione-delle-vm)
    - [Ottimizzazione della Rete](#ottimizzazione-della-rete)
    - [Orchestrazione](#orchestrazione)
  - [Soluzioni in Ambito Industriale e di Ricerca](#soluzioni-in-ambito-industriale-e-di-ricerca)
    - [Soluzione Basata sull'Utilizzo](#soluzione-basata-sullutilizzo)

# Gestione del Data Center

La gestione del data center è un *problema complesso* per la quantità di necessità in gioco, specie alcune in conflitto tra loro. In generale, si deve cercare di *ridurre i costi massimizzando il profitto*, il tutto cercando di garantire le *SLA* (*Service Level Agreement*, requisiti che devono essere rispettati dal *Service Provider* nei confronti dei propri clienti). Il problema della gestione può essere visto come un **problema di ottimizzazione**, nel quale bisogna tenere conto di diverse ***metriche di performance***:

- **KEY PERFORMANCE INDICATOR** (***KPI***): le metriche di performance del sistema
- **VINCOLI**: solitamente requisiti aggiuntivi del sistema (es. *tempi di servizio*)

## Metriche di Performance

Per descrivere le performance di un data center è possibile considerare diversi aspetti:

- Consumo Energetico
- SLA
- Failure Rate
- Utilizzo delle Risorse
- Affidabilità / Disponibilità

 ### Consumo Energetico

Per considerare il consumo energetico di cui ha bisogno un data center è possibile pensare alle singole componenti del consumo: *computazione*, *networking*, *storage*, e *cooling*. La nuova frontiera tende verso i ***green data center***: siccome i data center sono strutture *molto golose di risorse*, sarebbe ideale *limitare il consumo di brown energy* (*non rinnovabile*), promuovendo il consumo di *energia green*.

### Service Level Agreement (SLA)

Il SLA fa riferimento ai requisiti contrattuali che il sistema deve rispettare. I requisiti si esprimono solitamente sotto forma di ***tempi di risposta***, ***throughput*** e ***disponibilità del sistema***. Per rappresentare il **tempo di risposta** del sistema è necessario prendere in considerazione un intervallo di tempo sensato: una finestra di *24h* non avrebbe senso se il periodo per gran parte del tempo durante la giornata è inattivo, per questo viene solitamente calcolata in una finestra di pochi minuti. Il tempo di risposta inoltre non può essere preso dai log, che tengono conto anche delle *tempistiche lato client*. Trattandosi di una **variabile aleatoria**, rappresentata come *valore medio* o *90-percentile*, è necessario utilizzare una **funzione cumulativa di probabilità** (*integrale della densità di probabilità*): ponendo sull'***asse delle X i valori*** (*istanti di tempo*) e sull'***asse delle Y*** la probabilità.

Il SLA talvolta può essere garantito all'interno di certe ***soglie di carico***. All'aumentare del carico del sistema aumenta la probabilità di accodamento delle richieste.

### Utilizzo delle Risorse

**Utilizzo della CPU**:

La variazione del carico ha un notevole impatto anche sul ***funzionamento della CPU*** e in particolar modo sulla sua ***temperatura***. L'improvvisa accensione e spegnimento di un server, può causare uno ***shock termico***, che va a ***accorciare la vita dei componenti***. L'utilizzo della CPU è un parametro da tenere sotto controllo per le performance del sistema, ed è possibile farlo guardando *gli istanti di tempo che questa trascorre in stato IDLE*, ma anche considerandone il **carico**, considerando *il numero di processi attivi in coda di esecuzione che può scegliere lo schedule*.

La **probabilità di un server di essere occupato** si esprime come $\rho = \frac{\lambda}{\mu}$. Dove $\lambda$ è *frequenza di arrivo delle richieste* (*tasso di arrivo*), mentre $\mu$ è il *frequenza con cui le richieste vengono soddisfatte* (*tasso di servizio*). 

**Utilizzo del Network**:

Un'altra risorsa del sistema. È possibile studiarne l'utilizzo in maniera analoga a quanto visto con la CPU, guardandone l'***utilizzo dei canali di rete***, facendo però attenzione al fatto che la *banda teorica* dei dispositivi non può essere raggiunta.

## Modelli di Performance

### Modello Energetico

Con un modello energetico è possibile misurare il *consumo energetico* in un sistema. Nel caso più semplice si considera una ***dipendenza lineare tra l'utilizzo del server e il consumo energetico***. Utilizzando modelli più complessi molte componenti del sistema verrebbero stimate, e potrebbero essere causa di errori. Alternativamente si possono usare modelli ***Dynamic Voltage / Frequency Scaling*** (*DVFS*), dove l'energia spesa varia con un *fattore cubico della frequenza del processore*. Ulteriori modelli di questo tipo possono basarsi sull'utilizzo del disco o sul trasferimento dei dati (*utilizzo della rete*).

### Modelli Basati su Sistemi a Coda

In questi modelli si considerano i ***sistemi a coda*** (con *accodamento di richieste*). Non serve che il modello ritorni un risultato preciso, ma basta conoscere almeno l'*ordine di grandezza per sapere se è necessario scalare o meno*.

#### Notazione dei Sistemi a Coda

I sistemi a coda vengono definiti mediante la seguente sintassi: 
$$
\text{\{Processo di Arrivo\}/\{Processo di Servizio\}/Numero di Servitori/Lunghezza della Coda\}}
$$
Se la lunghezza della coda non viene specificata si assume che abbia *lunghezza infinita*. I Processi possono essere classificati con delle lettere, ciascuna corrispondente a una *distribuzione di probabilità*:

- **M** : *Processo di Poisson* (*M*  sta per *Memory Less*, caratterizzato dall'*assenza memoria*). Viene solitamente utilizzata per ***richieste non correlate tra loro***, come ad esempio le *sessioni utente*.
- **D** : *Processo Deterministico*
- **G**: *Processo Generico* (solitamente *Gaussiana* o *Log Normale*, una *Gaussiana con sopra un Logaritmico*)

#### M/M/1

Il tempo di risposta aumenta normalmente con l'aumento dell'utilizzazione (e quindi del carico) del sistema. Il *Tempo di Risposta* $T_R$ è dato da: $T_R = \frac{1}{\mu-\lambda}$ .

#### M/G/1 

In questi sistemi viene utilizzato il *Teorema PASTA* (*Poisson Arrival See Time Average*). Vengono introdotti diversi parametri come il ***tempo di attesa medio*** $E[W]$, il ***tempo di risposta medio*** $E[T]$ e il ***tempo medio di servizio*** $E[S]=\frac{1}{\mu}$. In particolare, analizzando la formula del tempo di attesa medio, questo è dato da:
$$
E[W] = \frac{1+C_v^2}{2}+\frac{\rho}{1-\rho}
$$
Dove $C_v^2$ è il ***coefficiente di variazione***, ovvero il ***rapporto tra la deviazione standard e il valore medio***, il quale ***descrive la variazione del tempo di servizio***. Per *Poisson* il valore di questo coefficiente è $1$: trattandosi di sistemi senza memoria, questi tengono conto solo dello *stato attuale* del sistema.

#### G/G/N

Sistema Generico, senza restrizioni sul tipo di distribuzione dei processi di arrivo o di servizio. Anche il numero di servitori viene indicato con un numero $n$ di servitori generici. Un sistema di questo tipo può essere usato per calcolare il ***tempo di risposta*** di un sistema generico.

### Modelli Basati sull'Affidabilità o Disponibilità

L'**Affidabilità** e la **Disponibilità** del sistema sono solitamente usati come **vincoli** di un *modello*. Bisogna tenere conto di ***come sono collegati i sistemi***: se in serie o in parallelo, del loro ***comportamento in caso di failure*** e del loro ***livello di replicazione***. Inoltre, è necessario distinguere se si utilizza un ***singolo data center*** o ***multipli data center***, scelta che comporta problemi differenti: se si fa uso di più data center le ***decisioni di scaling*** devono essere prese ***entro un certo orizzonte temporale*** (*ore prima*), e bisogna fare uso di ***predittori di carico***, al contrario con un singolo data center le decisioni richiedono meno anticipo, ma si ha meno elasticità.

### Modelli Economici

Questi **modelli** sono ***relativi ai costi***. Se un *Provider* deve pensare a *massimizzare il ricavo*, un cliente da lato suo deve *minimizzare la spesa*. Un Provider ha a disposizione ***macchine diverse***, con diverse caratteristiche, di diversa potenza e soprattutto con ***performance differenti***. Queste macchine possono essere vendute a Customer oppure alla concorrenza (*altri Provider*) qualora questa ne abbia bisogno. Bisogna quindi vedere quanta ***potenza di calcolo vendere quanta tenersi da parte***. Queste macchine sono:

- **Istanze di VM Dedicate**: macchine economiche, il cui utilizzo si paga anticipo per essere utilizzate mesi o anni, sempre disponibili
- **Istanze di VM On Demand**: costi alti (*3 x quelle dedicate*), il cui utilizzo si paga per un breve periodo (ore), sempre disponibili
- **Spot VM**: macchine generalmente vendute all'asta con l'intento di fare un profitto (anche se minimo), anche queste pagate per un breve termine, possono essere *indisponibili*. Se si paga un'ora e la macchina risulta indisponibile per un po' di tempo, quel tempo viene rimborsato.

## Variabili Decisionali

### Posizionamento delle VM

Il Problema del *Posizionamento delle VM* può essere visto come un ***bin packing problem multidimensionale***, in quanto per ogni macchina ***ci sono in gioco diverse risorse*** (*RAM*, CPU, ecc...). Inoltre, le decisioni che si prendono devono andare ***bene per un po' di tempo***. Per semplificare questo problema, è possibile *non guardarlo in termini di numero di VM*, ma di ***classi di servizio***, considerando il ***numero di repliche per ciascun servizio***.

> REF *Paper*. *"Posizionamento Scalabile e Automatico delle VM con Similarità Comportamentali"* del Prof. Lancellotti
>
> Si vuole diminuire il Numero di server accesi, dove la formula:
> $$
> \min{\sum_{s\in S}} O_s
> $$
> rappresenta il *vettore booleano* che indica se il server è acceso o spento, mentre:
> $$
> \sum_{s \in S}I_{m,s} = 1
> $$
> rappresenta un *vettore booleano* che *ha valore $1$* se e solo la *macchina $m$* è *allocata sul server $s$*. Una macchina può trovarsi su un solo server, quindi deve per forza essere $1$. Si ha che le risorse utilizzate dal server devono essere minori delle risorse disponibili sul server ($V_{r,s}$) quando questo è acceso ($O_s$):
> $$
> \forall s, \forall r, \forall t \quad \sum R_i \cdot r(t) \cdot I_{m,s} < V_{r,s} \cdot O_s
> $$

### Migrazione delle VM

La **migrazione** consiste nello ***spostamento di una VM da un server a un altro***, e si verifica solitamente quando i server vengono sotto-utilizzati: questi vengono spenti e le macchine spostate su altri server più attivi, in modo da poter spegnere i primi risparmiando risorse ed energia. Queste variabile vengono identificate con i termini $g_{m,s}^{-}$ quando una *macchina esce da un server*, $g_{m,s}^{+}$ quando *entra*.

### Ottimizzazione della Rete

È necessario mappare il modo in cui le macchine comunicano tra loro in maniera ottimale all'interno della rete. Macchine che comunicano tra loro *devono stare vicine* (stesso *rack o cluster*).

### Orchestrazione

Per il **Deployment** del sistema si devono considerare i ***microservizi*** e il ***carico atteso su ciascuno di essi***, in base a questo si definisce il numero e il tipo di VM per ciascun servizio, tenendo conto dell'***evoluzione del suo carico in base alle richieste***, il tutto *minimizzando i costi*.

## Soluzioni in Ambito Industriale e di Ricerca

### Soluzione Basata sull'Utilizzo

Si tratta della "regola del pollice" in ambito cloud: viene utilizzata per la **server consolidation**, in modo da ***evitare server sovraccarichi*** e ***server sottoutilizzati***, viene anche utilizzata per le ***decisioni di scaling*** e può essere affiancata ad ***algoritmi di predizione del carico***. Si utilizzano ***due soglie***, indicando con $U$ l'utilizzo del server:

- $U > 80\%$ : parte del carico viene spostato su un nuovo server (*bilanciamento del carico*)
- $U < 20\%$ : il carico viene distribuito su altri server (*non sovraccarichi*) e il server viene spento (*migrazione*)

I predittori di carico non sono molto utilizzati in ambito industriale, perché ***non sempre il carico e predicibile*** e talvolta è meglio *reagire in ritardo piuttosto che reagire male*.

> REF *Paper*. "*Ecocloud*"
>
> La migrazione può essere visto come un *processo stocastico*. Ad ogni VM è associata una *probabilità* di essere ***oggetto*** o ***target*** di una ***migrazione***. In questo modo, nodi con un'alta utilizzazione hanno una probabilità alta di essere *oggetto di migrazione*, mentre quelli sotto utilizzati hanno una probabilità alta di essere *target della migrazione*. Questo permette lo spostamento del sistema su una ***condizione ideale*** dove i ***nodi hanno un'utilizzazione medio-alta***. 
>
> Questa visione è stata confrontata con altre *alternative euristiche* come ***Best Fit Decreasing***, che tiene conto di *molti parametri* e una *visione completa del data center*, riuscendo comunque a ottenere buoni risultati.

> REF *Paper*. "*Energy Aware Resource Allocation* - *Modified Best Fit Decresing*" (*MBFD*)
>
> Il posizionamento delle VM guarda al ***minimizzare il consumo energetico***. La selezione delle macchine da migrare nei server in sovraccarico avviene cercando di ***minimizzare il numero di migrazioni*** e ***minimizzando il numero di accensioni e spegnimenti***.  Su questa base, vengono scelte per la migrazione le ***macchine più vicine alla soglia***, oppure ***in maniera casuale***.

> REF. *Paper* "*Hierarchical*"
>
> Si considerano due tipi di problemi: quelli a lungo termine e quelli a breve termine. Quelli a lungo termine consistono nel ***distribuire il carico su più data center cloud***, quello a breve termine riguarda l'***allocazione delle VM***. I problemi a lungo termine lavorano su ***base a oraria***, mentre quelli a breve termine lavorano su ***time slot***: si osserva la crescita tra un time slot e l'altro e si guarda se vale la pena acquistare una VM o sforare un requisito della SLA e pagare una penale.

> REF. *Paper* "*Optimizing Network Utilization* - *VMPlanner*"
>
> Si cerca di *posizionare correttamente le VM* in modo da ***ridurre i sovraccarichi della rete***, in particolare alleggerendo la *parte core della rete*. Essendo un *problema NP Hard*, questo viene diviso in sottoproblemi, ciascuno *NP completo*:
>
> 1. ***Ricerca delle macchine che comunicano*** di più
> 2. ***Mapping delle Macchine sui Racks***
> 3. ***Mapping dei Flussi di Traffico*** sulla Rete del data center (per nodi potenzialmente lontani)
>
> La soluzione ideale consiste nell'implementazione di un'***infrastruttura di rete adattiva***, in grado di gestire i flussi di traffico indipendentemente dalla loro dimensione. I nodi all'interno della rete *riconoscono il tipo di flusso* e ricostruiscono le loro matrici per la comunicazione.

> REF. *Paper* "*Joint Minimization of the Energy Cost* - *JCDME*" 
>
> Approccio che ***cerca una funzione per minimizzare il costo energetico*** tenendo conto di ***tanti parametri***, a ciascuno dei quali ***viene associato un peso***. La **migrazione** è un'***operazione costosa*** in termini di ***consumo energetico***, pertanto affinché la decisione abbia senso questo ***costo deve essere spalmato su più unità di tempo***. Se si ricorre alla migrazione bisogna essere sicuri che in seguito il sistema *continuerà a consumare e a richiedere un livello più basso di energia per una quantità di tempo che giustifichi la scelta*.