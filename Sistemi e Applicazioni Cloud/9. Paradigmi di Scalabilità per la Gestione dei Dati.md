- [Paradigmi di Scalabilità per la Gestione dei Dati](#paradigmi-di-scalabilità-per-la-gestione-dei-dati)
  - [Replicazione dei Dati](#replicazione-dei-dati)
    - [Metodi di Sincronizzazione](#metodi-di-sincronizzazione)
  - [Approcci di Scalabilità](#approcci-di-scalabilità)
    - [Database non Relazionali](#database-non-relazionali)
    - [Replicazione Parziale](#replicazione-parziale)
      - [Web Caching](#web-caching)
        - [Limiti](#limiti)
        - [Modelli di Business](#modelli-di-business)
        - [Caching Cooperativo](#caching-cooperativo)
  - [Content Delivery Network (CDN)](#content-delivery-network-cdn)
    - [Architettura](#architettura)
    - [Recupero dei Contenuti](#recupero-dei-contenuti)

# Paradigmi di Scalabilità per la Gestione dei Dati

Quando si fa riferimento alla *scalabilità di un sistema*, si fa riferimento a due tipi di scalabilità:

- **SCALABILITÀ VERTICALE**: acquisto di nuove tecnologie e nuovo hardware
- **SCALABILITÀ ORIZZONTALE**: affiancamento di nuove macchine

*Per aumentare le prestazioni è inevitabile **replicare***. La replicazione di un sistema a sua volta può essere **totale** o **parziale**: la prima viene solitamente fatta per *aumentare la disponibilità del sistema*, la seconda *per motivi di performance*. Maggiore è il livello di replicazione del sistema, più **difficoltà** si ha nell'assicurare la **consistenza dei dati** (*mantenimento delle copie allineate*).

## Replicazione dei Dati

In generale, quando si parla di **replicazione**, bisogna *trovare un compromesso* tra l'avere un'***alta disponibilità dei dati*** (*garantendo una consistenza forte*) e l'avere un ***alto livello di performance e scalabilità***. In base al numero di copie da mantenere aggiornate, si hanno costi differenti, pertanto è necessario trovare il miglior compromesso, facendo ad esempio in modo di garantire che *prima o poi una modifica venga propagata anche sulle altre macchine*: solitamente si cerca di assicurare una *forte consistenza* ai dati a tutti quegli utenti che accedono dalle stesse aree geografiche. Si tiene conto di due fattori:

- **SINCRONIZZAZIONE DEI DATI**

  L'utente deve rimanere all'oscuro dell'esistenza della replicazione: non deve preoccuparsi della replica del dato a cui accede così come della macchina. L'approccio più semplice per garantire una **consistenza forte** è mantenere un sistema con ***un server master*** e ***delle copie di server primari***. In questo modo le modifiche in scrittura avvengono sempre sul master, che può propagarle agli altri *immediatamente* o *periodicamente*.

- **SISTEMI DI CONTROLLO PER LA CONCORRENZA**

  Il problema del master è che *riceve molteplici richieste*, quindi occorre ***un meccanismo di controllo dei flussi per conoscere lo stato consistente***. Il master deve **serializzare le richieste** creando una **lista ordinata**.

Mediante questo approccio è possibile garantire un'***elevato livello di disponibilità e di performance***. Ogni servizio deve implementare una propria soluzione per la geo-distribuzione delle repliche.

### Metodi di Sincronizzazione

Per permettere alle **repliche** di **comunicare** vengono utilizzati dei ***protocolli di consenso***. Il più famoso è il **two-phase commit**.

**TWO-PHASE COMMIT**: Il master prende la prima richiesta e manda il "*prepare to commit*" agli altri con la transazione da eseguire. Le repliche iniziano la *transazione localmente*, *fermandosi* appena *prima* del *commit*. In seguito, inviano al master l'*esito delle operazioni*, il quale, in base alle risposte, invia o meno l'*ordine di esecuzione del commit*. Se anche una sola copia non va a buon fine manda l'*ordine di rollback*.

Per garantire una migliore disponibilità dei dati, si è pensato di utilizzare dei **server secondari** (normalmente utilizzati per il backup) in modo da aumentare le performance del sistema delegando ad essi le ***operazioni di lettura dati***. Essendo server originariamente pensati per il backup, devono essere geograficamente distribuiti in maniera opportuna (almeno *30Km* dai primari). A seconda che il server sia primario o secondario, il livello di consistenza che si garantisce è differente: in un ***server primario*** viene normalmente assicurata una ***strong consistency***, mentre in una ***server secondario*** una ***weak consistency*** (*tempi più lunghi di sincronizzazione*). Due server secondari si scambiano informazioni di tanto in tanto, se i loro dati sono *indipendenti* è sufficiente *fare il merge*, altrimenti devono trovare l'ordine corretto delle operazioni (*utilizzando ad esempio il timestamp*).

## Approcci di Scalabilità

### Database non Relazionali

*NoSQL* abbandona il paradigma *ACID* (*Atomicità, Consistenza, Isolamento, Durabilità*) e abbraccia le ***Base Properties***, aumentando la scalabilità del sistema e diminuendo la consistenza.

- **BASICALLY AVAILABLE**: viene utilizzata la *replicazione* per *aumentare la disponibilità dei dati*
- **SOFT STATE**: permette ai dati di essere *in uno stato inconsistente*
- **EVENTUALLY CONSISTENT**: assicura che prima o poi la consistenza dei dati sarà raggiunta

### Replicazione Parziale

Poiché all'aumentare del numero di server primari la gestibilità del sistema diventa più complessa (a causa della *strong consistency)*, una soluzione alternativa consiste nell'utilizzare i server secondari. Non un numero eccessivamente grande, ma il giusto che garantisca un certo aumento di performance del sistema. L'idea è quella di mettere ***tra il client e il primary server un proxy*** (*server intermediario*). Il proxy deve essere quanto più vicino al client possibile, non una vicinanza geografica, ma decisa in base alla banda a disposizione.

#### Web Caching

Affinché il Proxy contenga i dati utili al client, è necessario che implementi un *meccanismo di caching*:

- **SPATIAL LOCALITY**: se un client accede a un dato, è probabile che i prossimi dati a cui accede siano dati vicini al precedente (*stesso storage*)
- **TEMPORAL LOCALITY**: se un client accede a un dato, è probabile che debba accedervi ancora (*ha senso portarlo su una cache*)

Il ***caching è efficace quando è coerente con i due principi*** di *spatial e temporal locality*. Quando il client trova la risorsa all'interno del cache server si parla di **cache hit**, altrimenti si parla di **cache miss**. Come metrica di performance si utilizza la **cache hit rate**, che misura il *numero di cache hit in un intervallo di tempo*. A seconda del suo funzionamento si distinguono due tipologie di proxy: 

- **PROXY SERVER** (*PULL*): il contenuto viene caricato sul server in seguito a una *cache miss*
- **REVERSE PROXY** (*PUSH*): i contenuti sono *pre-caricati* sui server dai server primari

##### Limiti

Il limite più grande del web caching sta nel fatto che *molti contenuti non sono cachabili*: dati volatili (*mercato finanziario*), dati dinamici risultanti da parametri, dati criptati e dati di grandi dimensioni come i *video*. Per salvare questi ultimi in un sistema proxy è prima necessario scaricare il *content manifest* (metadati del video) dal server primario, nel quale è specificato il numero dei segmenti video e la loro lunghezza. Poiché questi oggetti sono *oggetti statici*, possono essere *cachati* e scaricati ad una certa risoluzione dai client mediante delle richieste HTTP.

##### Modelli di Business

A seconda del controllo che ha il *Content Provider* (*CP*) e quello lasciato al *Content Consumer* (*CS*) è possibile individuare diversi modelli di business:

1. Tutte le infrastrutture appartengono al CP che le gestisce
2. I server primari (e i master) appartengono al CP, mentre i server secondari sono contattati dai CS (*client*) ma vengono gestiti da terzi
3. Il master appartiene al CP che gestisce i server primari di terzi, mentre i server secondari possono non essere utilizzati o appartenere ad altri
4. Analogo al precedente, ma i server primari appartengono a un servizio cloud
5. Il CP si limita a creare i contenuti, utilizzando le infrastrutture (*master compreso*) di terzi (*cloud provider o CDN*)

##### Caching Cooperativo

Dato che in uno scenario reale in una rete sono presenti *molteplici proxy server*, questi ***possono comunicare tra loro*** in caso di *cache miss prima di passare dal content provider*. A seconda della tipologia dei cache server si distingue una caching cooperativo di tipo ***pubblico*** quando i *cache server appartengono a governi o agenzie di stato*, ***privato*** altrimenti  (*ISP* o *CDN*). Le principali modalità di cooperazione sono:

- **QUERY BASED**: *event-driven*, in seguito a un cache miss
- **INFORMED BASED**: *comunicazione periodica e sincrona*

## Content Delivery Network (CDN)

Il termine fa riferimento all'***acquisto di un servizio di content delivery da un'azienda che si occupa di replicare i dati***. I contenuti vengono propagati attraverso delle ***reti di reverse proxy***. L'utilizzo di queste reti *riduce la latenza percepita dall'utente*, il *traffico di rete*, e *aumenta la sicurezza dei sistemi evitando attacchi di tipo DoS* (attaccare una rete risulta più difficile). Il **"CONTENUTO"** (*content*) che la rete offre all'utente è generalmente qualcosa per cui l'utente è disposto a pagare: *streaming video*, *audio*, ecc... È quindi opportuno utilizzare dei metodi di ***selective caching*** per capire quali possono essere i contenuti di maggiore interesse per gli utenti, quali contenuti replicare, in che numero e come distribuirli, il tutto garantendo ai proxy dei buoni risultati in termini di *cache hit rates*.  

### Architettura

La rete si divide su due livelli mediante due tipologie di server:

- **CORE SERVER**: si occupa della parte di computazione dati. Siccome sono dati "a pagamento" devono essere codificati e bisogna tenere dei metadati. I server in questa parte della rete si occupano di questa parte di gestione dei dati.
- **EDGE SERVER**: utilizzati dai client per reperire i loro dati

### Recupero dei Contenuti

I *server CDN* possono anche essere utilizzati per reperire *contenuti dinamici all'interno di pagine web*. Ci sono *due scenari possibili*: 

1. ***first hit at the Origin Server***: la *pagina web* viene mantenuta su un *origin server* e i suoi contenuti multimediali su un *Server CDN* (questi contenuti hanno un *URL* diverso rispetto ai contenuti che si stanno visitando). La pagina viene richiesta all'*Origin Server*, una volta ricevuta il browser fa il *parsing della pagina HTML* per caricare i ***contenuti embedded*** che come *dominio* fanno ***riferimento al server della CDN***.
2. ***first hit at CDN Server***: in questo caso il *client* richiede la ***pagina*** al *Server CDN*, dove la pagina *viene **precaricata*** (*home page + oggetti embedded*). Quando il client ***specifica un dominio*** viene dirottato su uno dei ***edge server*** della *CDN*. Il tutto può essere gestito con un **sistema di *Server DNS***, dove il *DNS del Customer* risponde al client rimandandolo al *DNS della CDN*, che risolve la richiesta indirizzando il client a uno dei suoi *CDN Server*.

> **AKAMAI - CDN Leader**
>
> Akamai è l'azienda Leader del Mercato delle CDN. Tratta circa il *30%* dell'intero traffico web e tratta il traffico di diversi clienti importanti: eventi sportivi (NBA, FIFA), Social Network (MSN), marchi di videogiochi (*Playstation*, *Nintendo*). La rete Akamai si aggiorna di continuo *analizzando le velocità di rete*, *il carico* e *le performance dei suoi autonomous system*, mappando ogni classe di indirizzo IP su un determinato server cluster. In caso di failure di quest'ultimi provvede immediatamente a rimappare il tutto.
