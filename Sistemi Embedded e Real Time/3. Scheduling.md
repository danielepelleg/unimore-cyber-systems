- [Introduzione](#introduzione)
  - [Task e Jobs](#task-e-jobs)
    - [Stato di Transizione dei Task](#stato-di-transizione-dei-task)
  - [Scheduling](#scheduling)
    - [Schedule](#schedule)
  - [Task Real Time](#task-real-time)
    - [Criticalità del Task](#criticalità-del-task)
    - [Modalità di Attivazione](#modalità-di-attivazione)
      - [Modello Periodico](#modello-periodico)
      - [Modello Aperiodico](#modello-aperiodico)
      - [Modello Sporadico](#modello-sporadico)
    - [Tipologie di Vincoli](#tipologie-di-vincoli)
      - [Vincoli Temporali](#vincoli-temporali)
      - [Vincoli di Precedenza](#vincoli-di-precedenza)
      - [Vincoli di Risorsa](#vincoli-di-risorsa)
  - [Anomalie di Scheduling](#anomalie-di-scheduling)
    - [Aggiunta di un Processore](#aggiunta-di-un-processore)
    - [Task più Corti](#task-più-corti)
    - [Eliminazione dei Vincoli di Precedenza](#eliminazione-dei-vincoli-di-precedenza)
    - [Processore più Veloce](#processore-più-veloce)
    - [Inserimento di un Ritardo](#inserimento-di-un-ritardo)
- [Scheduling](#scheduling-1)
  - [Tipologie](#tipologie)
    - [Long Term](#long-term)
    - [Medium Term](#medium-term)
    - [Short Term](#short-term)
  - [Criteri di Selezione dello Scheduling](#criteri-di-selezione-dello-scheduling)
  - [CPU-Bound e I/O Bound](#cpu-bound-e-io-bound)
  - [Semplificazione del Problema](#semplificazione-del-problema)
- [Algoritmi di Scheduling non Real-Time](#algoritmi-di-scheduling-non-real-time)
  - [First In First Out (FIFO o FCFS)](#first-in-first-out-fifo-o-fcfs)
  - [Shortest Job FIrst (SJF)](#shortest-job-first-sjf)
  - [Priority Scheduling](#priority-scheduling)
  - [Round Robin](#round-robin)
    - [Round Robin basato su Priorità](#round-robin-basato-su-priorità)
- [Algoritmi di Scheduling Real Time](#algoritmi-di-scheduling-real-time)
  - [Earliest Due Date (EDD)](#earliest-due-date-edd)
  - [Earliest Deadline First (EDF)](#earliest-deadline-first-edf)
- [Task Periodici e Sporadici](#task-periodici-e-sporadici)
  - [Timeline Scheduling](#timeline-scheduling)
    - [Vantaggi](#vantaggi)
    - [Svantaggi](#svantaggi)
    - [Problema dovuto all'Overload](#problema-dovuto-alloverload)
  - [Priority Scheduling](#priority-scheduling-1)
    - [Verificare la Schedulabilità](#verificare-la-schedulabilità)
      - [Esempio di Schedulabilità](#esempio-di-schedulabilità)
    - [Istante Critico](#istante-critico)
    - [Task Sporadici](#task-sporadici)
      - [Priorità Fissa](#priorità-fissa)
    - [Hyperbolic Bound](#hyperbolic-bound)
- [Scheduling a Priorità Dinamiche](#scheduling-a-priorità-dinamiche)
  - [Earliest Deadline First](#earliest-deadline-first)
    - [Vantaggi e Svantaggi](#vantaggi-e-svantaggi)
  - [Deadline Minore o Uguale al Periodo](#deadline-minore-o-uguale-al-periodo)
    - [Deadline Monotonic](#deadline-monotonic)
  - [Response Time Analysis](#response-time-analysis)
    - [Esempio](#esempio)
  - [Processor Demand](#processor-demand)
    - [Limitare la Complessità](#limitare-la-complessità)

# Introduzione

## Task e Jobs
Un task si può considerare come un'infinita sequenza di istanze (istruzioni) chiamate jobs, che sono eseguite da un processore fino al completamento. I job possono ripetersi *periodicamente* oppure in *maniera sporadica*. In genere, in un Sistema Operativo un task *può essere un processo* o *un thread*. Facciamo riferimento alla seguente sintassi quando parliamo di task:
- $S_i$: *start time* inizio dell'esecuzione
- $f_i$: *fine dell'esecuzione*. In questo istante di tempo viene eseguita l'ultima istruzione che il task deve eseguire.
- ↑ $r_i$ (o $a_i$, *arrival time*): il task *arriva in stato ready* ed è pronto ad eseguire (entra nella coda dei task pronti ad eseguire).

Il _numero di task_ che possono andare in esecuzione *dipende dal numero di core*.

### Stato di Transizione dei Task
- → READY : *activation*, il task viene creato per la prima volta
- READY → RUNNING : *dispatching*
- RUNNING → BLOCKED : *wait*
- BLOCKED → READY: *signal*
- RUNNING → READY: *preemption*
- RUNNING → : *termination*

A seconda di come si ordina la *ready queue*, cambia l'ordine di esecuzione dei task. L'ordine con la quale si decide di governare questa coda determina la *policy di scheduling* (o algoritmo di scheduling). Per mantenere una coda ordinata solitamente si paga in *inserimento* o in *estrazione*.

## Scheduling
Un algoritmo di scheduling si dice *preemptive*, se un task in esecuzione può essere sospeso temporaneamente per eseguirne un altro più importante, *non preemptive* altrimenti. Un algoritmo non preemptive *non permette* la preemption di un task anche nel caso in cui arrivi un task con priorità maggiore: solo una volta che il task in esecuzione raggiunge il suo completamento può andare in esecuzione il prossimo. Gli algoritmi non preemptive, seppur siano di semplice implementazione (in questi algoritmi non c'è overhead dovuto alla latenza del context switch. nel quale si salva il contesto), possono comportare la *deadline miss* di diversi task, specie quando questi arrivano con *frequenza elevata*.

### Schedule
Con il termine si fa riferimento all'*assegnamento dei task al processore*. Lo schedule ci sa dire quale task va in esecuzione istante per istante. Possiamo definire lo schedule come un *mapping* $\sigma$:

$$
σ(t) = 
\begin{cases} 
  k > 0 \qquad \textnormal{se $τ _k$ sta eseguendo} \\ 
  0 \qquad \textnormal{se il processore è idle}
\end{cases}
$$

Quando il processore è *idle*, il Sistema Operativo aspetta degli input. L'intervallo di esecuzione di un task prende il nome di *time slice*.

## Task Real Time
I task real time si differenziano dagli altri per il concetto di *deadline*. Si possono avere deadline che coincidono con il periodo del task, oppure deadline *implicite* o *esplicite*. In questi sistemi possiamo introdurre diversi parametri:
- $C_i$ o *WCET* (*worst case execution time*): tempo di esecuzione del caso peggiore. *Configurazione* che causa il *ritardo maggiore*.
- $d_i$ : deadline *assoluta*, si tratta di un *istante $t$*
- $D_i$ : deadline *relativa*, si tratta di un *intervallo di tempo* dato da $d_i - r_i$

Altri parametri sono:
- **Lateness** ($L$) : *ritardo del task*. Dato dal $f_i - d_i$, se si finisce prima della deadline si ha un *negativo*
- **Tardiness** : Lateness  dove vengono eliminati i risultati negativi, ovvero quei casi in cui *il task finisce prima della deadline*. Viene definita come $max(0, L)$, il valore negativo viene messo a zero per evidenziare il fatto che *non c'è stato ritardo* nell'esecuzione.
- **Residual *WCET*** $c_i(t)$ : tempo che rimane da eseguire in un determinato istante di tempo (per questo dipende da un *t*). Durante l'istante di arrivo $r_i$ è pari a $c_i(r_i) = C_i$
- **Slack** : *margine di tempo* che rimane *prima* che il task raggiunga la sua *deadline* (e quindi avere un *deadline miss*). Viene definito come $d_i - t - c_i(t)$. Se mentre si sta eseguendo un task c'è preemption, ci da informazione su quanto tempo al massimo può essere sottratto il processore senza incorrere a un deadline miss.

### Criticità del Task
Le diverse tipologie di criticità si differenziano l'una dall'altra per le *conseguenze* che si hanno in caso di deadline miss.
- **HARD** Task : non è mai possibile violare una deadline (conseguenze molto serie, esempio del braccio meccanico che si deve muovere o di sensori)
- **SOFT** Task : a volte è possibile violare una deadline (esempio del pendolo inverso, user command interpretation, message displaying)
- **FIRM** Task : la violazione della deadline è consentita esclusivamente a determinati Jobs. Possiamo mancare la deadline, a patto che non ne vengano mancati troppi di fila. L'obiettivo è quindi quello di *ottimizzare la reattività*.

Un sistema operativo in grado di gestire gli hard task chiamato *hard real-time system*, utilizzato solitamente per l'acquisizione di sensori. La code base dei sistemi RTOS (*Realtime Operating Systems*) è molto più minimale, in quanto si tratta di sistemi che *devono essere predicibili*.

### Modalità di Attivazione
- **Time Driven** : il task è *attivato dal kernel* secondo degli *intervalli di tempo prestabiliti* (task periodico). 

- **Event Driven** : il task è attivato dallo *scatenarsi di un evento* o dall'*inovcazione esplicita di una primitiva di attivazione* (task aperiodico). In questi casi il prossimo job parte dopo il precedente: non si ha la certezza di quanto tempo dopo ciò accada. Nei task sporadici il prossimo job parte *almeno un periodo dopo la fine dell'esecuzione precedente*. Un sistema aperiodico non da grandi garanzie: il carico potenziale di un task sul sistema è potenzialmente infinito. Nei task sporadici è necessario conoscere il *minimal time arriving*.

#### Modello Periodico
Ai parametri introdotti precedentemente si aggiunge il Periodo $T_i$. Il *Periodo* è la distanza tra due invocazioni successive dello stesso task (tra due *arrival time* $r_i$ di due jobs appartenenti allo *stesso task*). Definito $ϕ_i$ l'*arrival time del primo job appartenente al task* si ha:

$$
\begin{cases} 
  r_{i,k} = \phi_i + (k-1) T_i \\ 
  d_{i,k} = r_{i,k} + D_i
\end{cases}
$$

In molti casi la deadline relativa e il periodo (tempo di interarrivo) coincidono, ma non sempre, in tal caso si parla di *Implicit Task Model*. Avere la deadline più piccola del periodo richiede di completare l'istanza un po' prima che il prossimo job abbia inizio. In questi casi: 
$$ D_i < T_i $$

#### Modello Aperiodico
In un modello *aperiodico* l'attivazione del job successivo avviene in modo più libero: non è presente un periodo o un minimo tempo di interarrivo. Non viene utilizzato in modo ricorrente, di solito viene utilizzato per *allarmi*.
$$r_{i,k+1} > r_{i,k}$$

#### Modello Sporadico
Nel modello *sporadico* si ha un *minimo tempo di interarrivo* $T_i$ tale che l'arrivo del *job successivo* avviene *dopo almeno un istante T_i* dal *job precedente*. I task possono arrivare anche con una periodicità T_i, a volte anche con una *periodicità maggiore*, ma *mai con una periodicità minore*.
$$r_{i, k+1} \geq r_{i,k} + T_i$$

### Tipologie di Vincoli
- **Vincoli di Tempo**: possono essere *deadline*, *vincoli di completamento*, *jitter*. Il jitter è la *variazione del Response Time* $R_i = f_i - r_i$, dato dalla differenza tra il *finishing time* e l'*arrival time*. A volte avere dei task lenti non è sempre un male, conoscere il ritardo dei task (ma anche il loro *jitter*) permette di gestirli meglio. 
- **Vincoli di Precedenza**: viene imposto un *ordinamento* nell'esecuzione di *task o job diversi*.
- **Vincoli di Risorsa**: talvolta i task hanno necessità di accedere a risorse condivise. Con vincoli di questo tipo, i task possono sincronizzarsi in modo da garantire l'accesso in mutua esclusione alla risorsa, così da garantire la consistenza dei dati.

#### Vincoli Temporali
I vincoli di tempo possono essere *espliciti* o *impliciti*. In quelli espliciti viene resa nota, in termini di secondi o millisecondi, la periodicità legata all'esecuzione di un determinato task. In quelli impliciti vengono fornite delle *latenze massime* relative all'esecuzione di un task (esempio della frenata nella guida autonoma, che deve essere fatta con una certa latenza dal rilevamento dell'ostacolo per garantire la sicurezza di tutti). Minore è il tempo di gestione dell'interrupt più performante è il sistema operativo.

#### Vincoli di Precedenza
Per capire con esattezza in che ordine eseguire determinati task, è possibile utilizzare un *Directed Acyclic Graph* (DAG).

#### Vincoli di Risorsa
Quando due task tentano di accedere alla stessa risorsa condivisa, il secondo deve bloccarsi in attesa che il primo finisca le proprie operazioni. Ciò garantisce la *consistenza dei dati*, ma il ritardo dovuto al locking potrebbe comunque causare una *deadline miss*. Quando si fa l'analisi della schedulabilità di un task set, bisogna pertanto considerare anche lo scenario in cui un task possa rimanere in attesa di accedere a risorse occupate da altri task con priorità maggiore. I vincoli di Risorsa, così come quelli di Precedenza sono tipicamente *legati all'utilizzo di semafori*.

## Anomalie di Scheduling
Supponiamo di voler provare a migliore le *condizioni operative* in cui opera un programma, ad esempio mediante un processore più veloce, task più corti o vincoli di precedenza. Talvolta, le cose anziché migliorare, potrebbero peggiorare.

**Scenario**:

Dati tre processori e il task set sottostante, supponiamo che ciascun task esegue per un numero determinato di unità di tempo, e che la loro priorità è tanto maggiore quando il loro indice è minore. 

$$
T_1 : 3 → T_9: 9 \\
T_2 : 2 \\ T_3: 2 \\
T_4 : 2 → T_5: 4 \\
 → T_6: 4 \\ → T_7: 4 \\  → T_8:4
$$

Tra questi sono presenti dei vincoli di precedenza indicati dalle frecce. All'inizio, nella coda dei processi pronti, sono presenti solo $T_1, T_2, T_3, T_4$. I primi tre task vengono messi in esecuzione sui tre processori a disposizione. Poiché il task $T_9$ non viene preemptato dal task $T_7$ a più alta priorità lo scheduler è di tipo *non preemptive*, e finisce all'istante $t_r = 12$.

<img src="C:\Users\Daniele\source\repos\unimore-cyber-systems\Sistemi Embedded e Real Time\resources\03_01_scheduling_anomalies_np.PNG" style="zoom:50%;" />

### Aggiunta di un Processore

Con l'aggiunta di un *quarto processore* ci si aspetterebbe immediatamente di avere delle performance migliori, tuttavia non è così:

<img src="C:\Users\Daniele\source\repos\unimore-cyber-systems\Sistemi Embedded e Real Time\resources\03_02_scheduling_anomalies_quarto_processore.PNG" style="zoom:50%;" />

Facendo partire il task $T_9$ per ultimo, 3 processori su 4 sono *idle*. Questo genere di problema prende il nome di *bin packing* (impacchettamento). L'aumento di un processore causa un *impacchettamento sfortunato*: rispetto a prima si finisce 3 istanti di tempo dopo. 

### Task più Corti

Si considera ora una *situazione analoga a quella inziale*, dove l'esecuzione per tutti i task è stata ridotta di un'unità di tempo.
$$
T_1 : 2 → T_9: 8 \\T_2 : 1 \\ T_3: 1 \\T_4 : 1 → T_5: 3 \\ → T_6: 3 \\ → T_7: 3 \\  → T_8:3
$$
<img src="C:\Users\Daniele\source\repos\unimore-cyber-systems\Sistemi Embedded e Real Time\resources\03_03_scheduling_anomalies_task_corti.PNG" style="zoom:50%;" />

Anche in questo caso si ottiene un *bin packing infelice*. Per diverso tempo si fanno due processori in stato *idle*. Anche in questo caso, diminuendo la durata dei task (ad esempio utilizzando *processori con una frequenza maggiore, quindi più veloci nell'esecuzione*) le cose vanno peggio.

### Eliminazione dei Vincoli di Precedenza

<img src="C:\Users\Daniele\source\repos\unimore-cyber-systems\Sistemi Embedded e Real Time\resources\03_04_scheduling_anomalies_senza_vincoli.PNG" style="zoom:50%;" />

Anche in questo caso, si ottiene un *impacchettamento sfortunato*.

### Processore più Veloce

Nell'immagine sottostante con il *colore giallo* si evidenzia l'*accesso a delle risorse condivise*. Nel primo caso comincia ad eseguire $\tau_2$, che viene interrotto da $\tau_1$ (task a priorità maggiore), che completa la sua esecuzione *prima dello scadere della sua deadline* (freccia rossa). Nel secondo scenario si considera lo stesso task set mandato in esecuzione su un processore due volte più veloce. Poiché $\tau_2$ finisce prima, può da subito fare una *lock* per accedere alle risorse condivise. Durante la sua esecuzione, il task $\tau_2$ viene preemptato da $\tau_1$ che però non avendo a disposizione la disposizione le risorse deve mettersi in attesa: il controllo ripassa a $\tau_2$, che finisce le operazioni sulle sue risorse condivise per poi passare immediatamente il controllo a $\tau_1$ che ora può fare una lock sulle stesse e operare, tuttavia nel momento in cui $\tau_1$ torna ad eseguire è già troppo tardi, e avviene una *deadline miss*. L'aver permesso al task $\tau_2$ di eseguire prima il locking della risorsa ha causato un bloccaggio significativo a $\tau_1$, che ha portato a un *deadline miss*. L'aumento della velocità del processore in questo caso ha comportato un *scenario peggiore*.

<img src="C:\Users\Daniele\source\repos\unimore-cyber-systems\Sistemi Embedded e Real Time\resources\03_05_scheduling_anomalies_faster_processor.PNG" style="zoom:50%;" />

### Inserimento di un Ritardo

Il ritardo può essere inserito mediante una *sleep* (o *nanosleep*) di un istante di tempo specificato.

<img src="C:\Users\Daniele\source\repos\unimore-cyber-systems\Sistemi Embedded e Real Time\resources\03_06_scheduling_anomalies_inserimento_ritardo.PNG" style="zoom:50%;" />

L'inserimento di un ritardo X non è un'operazione lineare, pertanto non sempre comporta un ritardo di X. Talvolta comporta un ritardo *molto maggiore di X*. 

L'approccio più sicuro prevede di dare *garanzie analitiche*. Bisogna assicurarsi che il task non violi la deadline qualsiasi sia l'arrivo dei jobs. Si privilegiano sistemi che hanno una *limitata variabilità nel tempo di esecuzione* e che siano *predicibili*.

# Scheduling
Il termine fa riferimento alla selezione di *quale processo o thread selezionare per essere mandato in esecuzione*. 
## Tipologie
In generale se ne distiguono di tre tipi:
- Long Term : capire se il sistema rimane sostenibile (schedulabile), quanti task il processore può supportare
- Short Term
- Medium Term

Nel corso affronteremo principalmente gli short, nei quali si deve decidere quale task mandare in esecuzione. I task soggetti a short scheduling si trovano già in stato di pronto.

### Long Term 

### Medium Term
Fa lo swap-in e lo spaw-out. Si decide se il task è gia presente nella memoria RAM.

### Short Term
Funzione di selezione che decide ual'è il prossimo processo (task) da eseguire. La modalità di decisione può essere *preemptive* (il task può essere interrotto in favore di un altro) o *non preemptive*.

## Criteri di Selezione dello Scheduling
Per valutare unoscheduler, in particolare per i sistemi real time è necessario guardare il tempo di risposta. Non a quello generico, ma al *worst case response tipe*. Inoltre si guarda il *throughput*, ovvero il livello di lavoro del processore. Anche la *perfromance* è importante, ma la *predicibilità*, specie in questi tipi di sistema lo è ancora di più: poter prevedere il comportamento di esecuzione rappresenta un grande vantaggio.

## CPU-Bound e I/O Bound
Un processo occupa del tempo nel processore, ma del tempo anche per approvigionare i dati necessari alla sua esecuzione. Questi dati devono essere portati in memoria RAM per essere elaborati dai processori. La memoria è sempre più un collo di bottiglia: in passato non era così, si guardava principalmentela frequenza del processore.

Il programma può avere un tempo di utilizzo della CPU, così come di periferiche di I/O. Un programma viene detto CPU bound se quando si interfacciano verso dispositivi esterni (I/O) non rilasciano la CPU.

**Approfondimento**:
Le prestazioni aumentano in relazione al numero di core nel sistema (non in relazione alla frequenza della CPU!). Sono i *core* che prendono ed elaborano dati. Legge di Moore: piu transistors sullo stesso chip → più capacità computazionale. Per "mangiare" questi dati (data crunching) ho bisogno di dispositivi hardware potenti: le schede video. Con una RAM direttamente sulla GPU c'è un unico bus su cui viaggiano i dati, conferendo un notevole aumento delle prestazioni. La banda rappresenta il modo in cui i dati vengono forniti dalla memoria alla CPU. Negli ultimi anni rimane la stessa. Stesso discorso per la latenza: ci vuole lo stesso tempo per leggere un dato di quanto ci volessero anni fa. Le prestazioni delle CPU sono aumetate notevolmente, tuttavia è la memoria che fa ancora da collo di bottiglia. Se la CPU, in termini di performance nette, migliora un 60% l'anno, la memoria rimane su un 7%. 

Lo schedule è *fattibile* quando, dati un insieme di task, soddisfa tutte le deadline. Un set di task è *schedulabile* se esiste almeno uno scenario in la schedule è fattibie.

- τ insieme di *n* task
- P insieme di *m* processori
- R insieme di *r* risorse

Questi rappresentano gli input del mio sistema. Dati questi tre input bisogna trovare uno schedule fattibile affinchè tutti i task rispettino ciascuno le loro deadline. Il problema dello scheduling è un *problema NP hard*. Si tratta di un problema per cui è estremamente difficile trovare una soluzione polinomiale, pertanto non presentano soluzioni note. Come si dimostra? Si prende un problema già appartenente a questa classe, e tramite un numero di passi polinomiale ti riconduci al problema di partenza (facendo ad esempio delle equivalenze).

## Semplificazione del Problema
In riferimento allo scheduling, si considera *un solo processore*. Inizialmente si partizionano i task sui vari processori: una volta che un task viene assegnato a un processore, non può cambiarlo. Ogni task viene considerato *preemptive*, e non hanno vincoli di precedenza tra loro. Nessun vincolo di tra le risorse (mutex o semafori). Essendo le ultime due semplificazioni molto restrittive, queste non saranno sempre valide in tutti gli scheduler.

La decisione dell'ordine esecuzione può essere fatta *online*, man mano che i task arrivano, oppure *offline*, ad esempio con uno scheduler a priorità fisse dove ciascun task viene accodato in base alla sua priorità. Con il termine priorità *statica* si fa riferimento all'impossibilità della priorità di un task di cambiare nel tempo, viene definita *dinamica* altrimenti, tipica di uno scheduler *deadline based*, dove ogni job appartanente a un task ha una priorità diversa. Uno scheduler *ottimo* trova uno schedule fattibile, mentre uno *best effort* fa il meglio che riesce, senza garantire che sia ottimo, o che riesca a trovare uno schedule fattibile.

# Algoritmi di Scheduling non Real-Time

## First In First Out (FIFO o FCFS)
I task vengono schedulati nell'ordine di arrivo. Questo scheduler *non presenta preemption*: un task non può essere "sorpassato" da uno che arriva dopo. Si tratta di un algoritmo di scheduling *dinamico*, la priorità di un task si basa completamente sul suo arrivo in coda, non è possibile conoscerlo a priori. Poichè non si conosce l'ordine di esecuzione a priori è un algoritmo *online* ed è *best effort*.

## Shortest Job FIrst (SJF)
Viene schedulato per primo il *task con il più piccolo tempo di computazione*. Il vantaggio di questo scheduler è il fatto che *minimizza il tempo di risposta medio*: non è buono per il task realtime, è esclusivamente importante che il task non superi la sua deadline. L'algoritmo può essere *sia preemptive che non preemptive*. L'algoritmo è statico: dipende dal solo tempo di computazione del task, che non cambia. La decisione dell'ordine di esecuzione può essere fattia *sia online che offline*. 

Per dimostrare che questo scheduler minimizza il tempo di risposta si procede con una Dimostrazione per Assurdo. Si prende un algoritmo σ ≠ SJF : affinchè sia diverso deve fare in modo, almeno una volta, di non eseguire il task con il più piccolo tempo di computazione presente nella coda dei task pronti. Minimizzare il tempo di risposta medio coincide con il minimizzare il finishing time medio (somma dei finishing time fratto il numero di task). SJF vince in tutte le simulazioni, pertanto si conferma il migliore nel conseguire l'obiettivo proposto (minimizzare il tempo di risposta).

## Priority Scheduling
Ad ogni task viene assegnata una priorità (solitamente un numero basso sta a rappresentare una priorità più alta). Il task con la priorità maggiore viene selezione per l'esecuzione, qualora due task avessero la stessa priorità vengono scelti mediante FCFS oppure Round Robin. I task generalmente hanno priorità fisse, pertanto hanno priorità fisse anche i task che li compongono. E' uno degli algoritmi di scheduling più utilizzato (anche nei sistemi real time). Il problema di questo scheduling è la *starvation*: task con una bassa priorità non eseguono mai. Una soluzione a questo problema potrebbe essere l'*aging*: più un task aspetta più la sua priorità aumenta, tuttavia così facendo i task non avrebbero più una priorità fissa, e non sarebbe più adatto ai sistemi realtime: nel momento in cui il task esegue potrebbe già essere troppo tardi e potrebbe mancare la sua deadline.


## Round Robin
I task vengono schedulati nell'ordine di arrivo (come in FCFS), ma il sistema presenta il concetto di *quanto di tempo*: ogni task che esegue lo fa per un determinato quanto di tempo. Se un task ha un tempo di esecuzione che super il quanto su di esso viene fatta preemption e ritorna in coda per essere rieseguito.

Definito *n* come il numero di task in un sistema. Per eseguire un task $C_i$ impiego $R_i = n*C_i$. Dove $R_i$ è il *tempo di risposta medio*. E' come se *virtualizzassimo il processore* in relazione al numero di task che abbiamo. Diminuire il quanto di tempo non è sempre una buona soluzione: bisogna considerare anche il tempo di overhead per il cambio di contesto. Se si sceglie un quanto di tempo troppo piccolo si ha solo un tempo di overhead e non si procede mai nell'esecuzione dei task.

### Round Robin basato su Priorità
Se un processo non riesce a finire la sua esecuzione, è possibile spostarlo su un altra coda FIFO con priorità maggiore. In questo modo viene eseguito più spesso ed è più propenso a finire liberando spazio. Vengono così create diverse code ciascuna con priorità differenti. QUesta policy di scheduling tenta di superare i limiti dei processi I/O bound.


# Algoritmi di Scheduling Real Time
I task possono essere scedulati secondo una deadline relativa, con un algoritmo a priorità statica, oppure secondo una *deadline assoluta*, con un *algoritmo a priorità dinamiche*. Consideriamo che tutti i task arrivino simultuaneamente già pronti per l'esecuzione e che la loro priorità sia conosciuta a priori. La *preemption non rappresenta un problema* per queste condizioni iniziali. Gli algoritmi per questo genere di sistemi *minimizzano il ritardo massimo*: non esiste alcun algoritmo che ha una lateness massima più bassa di EED (ha una lateness comunque negativa), e finisce quindi prima della deadline).

## Earliest Due Date (EDD)
## Earliest Deadline First (EDF)


# Task Periodici e Sporadici
Di seguito si considerano diversi algoritmi di scheduling per Task Periodici e Sporadici. Non si considerano quei task che vengono eseguiti una sola volta e poi terminano la loro esecuzione. Importante è la grandezza $T$ che è il Periodo.

## Timeline Scheduling
Chiamato anche *cycle executive* o *ciclici scheduling*, o ancora *table driving scheduling*. Viene implementato offline: ancora prima dell'esecuzione del primo task, si decide l'ordine di esecuzione. La loro esecuzione viene rappresentata in forma tabellare, e la tabella viene periodicamente ripetuta. Ha dei pregi e dei difetti: per costruzione, se tutto si comporta a dovere, si ha sempre conoscenza di ciò che succede. Se qualcosa nel sistema cambia, non si ha flessibilità. E' stato uno dei primi scheduler utilizzati, soprattutto in ambito militare.

L'asse del tempo viene divide in *intervalli di uguale lunghezza* chiamati *time slot*. Ogni task viene allocato in uno slot. Se si fa in modo che ogni task non superi mai il suo periodo, allora questo non sfoerà mai la sua deadline. Il *minor cycle* è la granularità con la quale cambio le decisioni di scheduling, mentre il *major cycle* è il ripetersi di un intero ciclo di esecuzione dei diversi task: ci dice ogni quanto tempo si ripete lo scheudule. Il tempo di esecuzione di due job deve essere sempre minore del *minor cycle*. Per un implementazione tipo non è neanche necessario il sistema operativo.

### Vantaggi
Quando tutto è noto a priori funziona molto bene.

### Svantaggi
Scheduler poco configurabile, non si abitua facilmente ad applicazioni che hanno una loro dinamicità. Si dimostra in questi casi uno *scheduler molto poco flessibile*.

### Problema dovuto all'Overload
Se due task eccedono il minor cyclo accade un effetto domino: lo scheduler comincia ad accumulare ritardo. Una soluzione al problema consiste nello *splittare un job in due (o più) diversi job*. Quando ho dei periodi armonici (il periodo di esecuzione di un job è multiplo del precedente) la situazione è più semplice. QUando ciò non accade, sono necessari degli *istanti di sincronizzazione* (interrupt). Ciò comporta un aumento dell'overhead.

## Priority Scheduling
Scheduler più utilizzato in assoluto. Ad ogni task è associata una priorità. RIchiede un sistema operativo con il supporto alle priorità. Come si assegnano queste priorità? Non conviene dare le priorità secondo la loro durata, ma è meglio assegnarla in base *ai periodi dei task*: più piccolo è il periodo maggiore sarà la priorità associata: *rate monotonic*. Questo è stato dimostrato essere l'assegnamento di priorità *ottimale* (non il migliore assoluto! EDF è anche migliore!). Tra tutti gli algoritmi *a priorità fisse*, assegnare la priorità *secondo il rate* è la scelta ottimale: se rate monotonic non ce la fa a schedulare un algoritmo, nessun altro algoritmo a priorità fisse può riuscirci. Anche se la durata di un job è appena più grande, non cambia più di tanto la sua schedulabilità.

[//]: <> "Possibile domanda per l'orale: Disegnare uno scheduler Rate Monotonic - slide 16"

### Verificare la Schedulabilità
Per valutarla è necessario calcolare *l'utilizzazione del processore*: somma delle utilizzazioni di ogni task, ovvero il rapporto tra *execution time* e *periodo*.
$$U_i = \frac{C_i}{T_i}$$

In genere un processore è *occupato ad eseguire un task* 9 volte su 10. Se $U_p > 1$ allora il processore è in *sovraccarico*. A noi interessa quando l'utilizzazione è *minore o uguale a 1*. Tuttavia avere *utilizzazione minore di 1* non è una condizione necessaria alla schedulabilità: è qua che entra in gioco *l'importanza dell'algoritmo*.

Una condizione *necessaria alla schedulabilità*, se non è realizzata, posso dedurre la *non schedulabilità*. Ma se questa è realizzata *non posso dedurre nulla*.

Se una condizione è *sufficiente alla schedulabilità*,
#### Esempio di Schedulabilità 
$$U_{TOT} =  \frac{C_1}{T_1} + \frac{C_2}{T_2} = \frac{2}{4} + \frac{2}{6} $$
$$C_1 = 2, T_1 = 4$$
$$C_1 = 2, T_1 = 6$$
Sotto all'utilizzo, ma non fattibile. La Preemption fa missare il processo $\tau _2$.

Se un task è schedulabile al pelo, allora aumentare uno solo dei due task comporta lo slittamento in avanti del successo (o dei successivi), e a una condizione di *deadline miss*. Quello che si vuole cercare è il *least Uperr Bound*. Se l'utilizzazione del processore è minore dell'upper bound ($Up < U_{lub}$), allora la condizione è sufficiente affinchè il task sia schedulabile con un algoritmo Rate Monotonic. E' stato dimostrato che per un set di n task periodici:
$$ U^{RM}_{lub} = n(2^{1/n}-1)$$

$$\text{per}\; n → \inf \qquad U_{lub}=\ln 2$$

### Istante Critico
[//]: <> "Possibile domanda per l'orale"
Si tratta del worst case della risposta. Se il tempo di risposta è maggiore della deadline non si viene schedulati. Si vuole quindi trovare la situazione di arrivo che massimizza il tempo di risposta. L'*arrivo sincrono* di tutti i task corrisponde *al tempo peggiore di risposta*. Per ogni task, il tempo di risposta massimo ad ogni task è quello degli altri task a priorità più alta di lui: un task con priorità più bassa non viene neanche considerato.

### Task Sporadici
Alternativa più comoda ai task periodici. $T_i$ diventa il *minimo tempo di interarrivo*. Consiste nel *minimo tempo che deve passare prima dell'arrivo del prossimo task*. Ciascun job $\tau _{ik}$ deve essere attivato con un ritardo $r_{ik} = r_{i(k-1)} + T_i$.

#### Priorità Fissa
Anche in questo caso: *il caso peggiore per i task sporadici è lo stesso per i periodici*. I task arrivano esattamente periodici in un istante $T_0$. Il caso sporadico si rifà a quello periodico. Ogni task viene rilasciato il prima possibile. Tutti i risultati ottenuti per i task periodici valgono anche per i periodici, compreso il calcolo di $U^{RM}_{lub}$.

### Hyperbolic Bound
Si vuole cercare di esplorare la zona da $1 < U < U_{lub}$, per massimizzare l'utilizzo del processore. Questo *hyperbolic bound* consiste nel fare la produttoria dell'utilizzazione di tutti i task *più 1*: se il risultato è minore di due allora il task set è *schedulabile*. E' un test sufficiente, ma non necessario. Migliora rispetto al precedente (aumenta la regione di discriminazione), ma non in modo troppo significativo.

I problemi che calcolano HB e LL hanno una *complessità lineare*.

# Scheduling a Priorità Dinamiche

## Earliest Deadline First
Fintanto che $U ⩽ 1$ con EDF l'esecuzione riesce sempre. E' ottimale per tutti gli algoritmi di scheduling. Permette di riempire compeltamente il processore. Si assumono sempre *deadline uguale al periodo* e *accesso alle risorse condiviso*. Con EDF tutti rispettano le proprie deadline. Quelli che prima con Rate Monotonic davano *deadline miss* ora riescono a eseguire.

[//]: <> "Possibile domanda per l'orale -> dimostrazione"

Per EDF il *least upper bound è uguale a 1*. 
$$U_{upb} = 1$$

Con EDF in generale si hanno *meno cambi di contesto*. A priorità fisse, se arriva un task ad alta priorità c'è *sempre preemption*. A priorità dinamiche l'algoritmo *concede di più*.

### Vantaggi e Svantaggi
Task Priority è prevedibile: un task comincia e finisce sempre nello stesso istante. Si ha una maggiore periodicità nei task ad alta priorità (sono come orologi). EDF è più variabile, finchè ha spazio prima della deadline se lo prende per ottimizzare l'utilizzo del processore. Questo comporta un jitter sempre variabile. EDF rimane comunque l'algoritmo più efficiente.

In caso di overload, RM non cambia il comportamento, cosa che accade invece per EDF. Esistono tuttavia dei modi per ridurre questi comportamenti indesiderati di EDF, attraverso i *real time server*.

Fino a questo momento si assumeva di avere una *deadline uguale al periodo*.

## Deadline Minore o Uguale al Periodo
Può essere comodo a volte dare a un task una deadline minore del suo periodo. Anche in questo caso EDF è l'algoritmo *ottimale*, tuttavia non è più possibile caricare l'*utilizzazione al 100%*. Per le tipologie fisse si utilizza ora *Deadline Monotonic*, anzichè *Rate Monotonic*. EDF algoritmo a priorità dinamiche, DM algoritmo a priorità fisse. 

### Deadline Monotonic
$$U_p = \sum_{i=1}^{n} \frac{C_i}{D_i}$$
Si dimostra che non è necessario arrivare fino all'iperperiodo (minimo comune multiplo del periodo tra due task) per vedere se un task set è schedulabile. E' sufficiente fermarsi al *primo idle point* (primo punto in cui il processore è inattivo).

$$\lim_{n→\infty} \sum_{i=1}^{n} \frac{1}{n} = ∞$$

Con deadline = periodo quando U>1 non è schedulabile, mentre quando la deadline è minore del periodo non si sa se è schedulabile se siamo sopra a $U_{lub}$.

## Response Time Analysis
Per andare a discriminare i task set schedulabili si utilizza un test basato sulla response time analysys: si calcola per ciascuno dei task il tempo di risposta in caso peggiore. QUesto processo è più iterattivo di quando si sommavano le singole utilizzazioni, pertanto risulta più complesso.

$$R_i = C_i + I_i$$
Questo test vale per *qualsiasi algoritmo a priorità fisse*.

$$I_{ik} = \lceil{\frac{R_i}{T_k}}\rceil $$
Rappresenta quante volte un task $τ _i$ sta dentro un $R_i$ (simbolo particolare).
La funzione a gradino (ceiling) non si presta per essere manipolata. Non si riesce a isolare. Nella soluzione iterativa si mette dentro un $R_i^0 = C_i$ in un passo $s$, iterando fino a quando non si raggiunge una *convergenza* $(R_i^{(s+1)}= R_i^{(s)})$. A noi interessa vedere se R ta dentro a D: se la supera non ha senso continuare, se perchè *sicuramente il task set non è schedulabile*. La complessità è *pseudopolinomiale*, dovuta a un polinomio e a un altro fattore: la *deadline*.

### Esempio
[//]: <> "Possibile domanda per l'orale "
Questo task set è schedulabile a priorità fisse (quindi senza EDF)? Che utilizzazione posso usare? I task vengono rappresentati come segue: $τ_i = C_i, D_i, T_i$
$$τ _1 = 3, 6$$
$$τ _2 = 7, 28$$
$$τ _3 = 5, 28, 30$$
Non posso utilizzare l'utilizzazione normale con la sommatoria dei $\frac{C_i}{T_i}$, devo utilizzare quello che somma i $\frac{C_i}{D_i}$:
$$U_{TOT} = \frac{3}{6} + \frac{7}{28} + \frac{5}{28} ≤ n \sqrt[n]{2} - 1 =$$
$$\frac{3}{6} + \frac{7}{28} + \frac{5}{28} ≤ 0,78 =$$
E' maggiore, quindi sembra risultare *non schedulabile*, tuttavia *non è ancora detto*: devo controllare con la *response time analysis*.
$$R_2 = 7+ ⌈\frac{R_2}{T_1}⌉\cdot3$$
$$R_2^{(0)} = 7$$
$$R_2^{(1)} = 13$$
$$R_2^{(2)} = 16$$
$$R_2^{(3)} = 16 ≤ D_2 = 28$$

$$R_3 = 5+ ⌈\frac{R_3}{T_i}⌉\cdot C_i = 5 + ⌈\frac{R_3}{6}⌉\cdot 3 + ⌈\frac{R_3}{28}⌉\cdot 7$$
$$R_3^{(1)} = 15$$
$$R_3^{(2)} = 21$$
$$R_3^{(3)} = 24 = R_3^{(4)} = R_3 ≤ D_3 $$

Ulteriore richiesta: Ricalcoliamo $R_3$ assumendo un execution time del task $τ _1$ pari a 7 $(C_i = 7)$:
$$R_3 = 7+ ⌈\frac{R_3}{T_i}⌉\cdot C_i = 7 + ⌈\frac{R_3}{6}⌉\cdot 3 + ⌈\frac{R_3}{28}⌉\cdot 7$$
$$R_3^{(1)} = 20$$
$$R_3^{(2)} = 26$$
$$R_3^{(3)} = 29 > D_3 $$
Non è più schedulabile.
Se il task set non è scheudlabile con Rate Monotonic, allora non è schedulabile con nessun algoritmo a priorità fissa.

## Processor Demand
EDF non è più utilizzabile con priorità dinamiche: occorre usare altri test. Qui in ogni intervallo si guarda il *tempo di computazione richiesto da ogni task*, che viene chiamato *processor demand*. Quando il task set che si chiede di eseguire è minore del tempo che si ha a disposizione, allora è schedulabile. Si elimina il contributo dei task che *non sono contenuti* dentro l'intervallo. Anche per EDF il caso peggiore è quello in cui *tutti i task vengono rilasciati nello stesso istante* $t_0$.
$$g(0, L) = ∑_{i=1}^{n} ⌊\frac{L + T_i - D_i}{T_i}⌋\cdot C_i$$

L'iperperiodo, nel caso più sfortunato è il *prodotto dei periodi*: $t^n$, ovvero con complessità esponenziale.

### Limitare la Complessità
Sostituendo al *floor* una parentesi tonda si ottiene $G$, per definizione si trova dunque qualcosa che è *maggiore o uguale*.
$$G(0, L) = ∑_{i=1}^{n} (\frac{L + T_i - D_i}{T_i})\cdot C_i$$

[//]: <> "Possibile domanda per l'orale -> Dimostrazione della Limiting L"
Si ricerca l'intersezione tra la maggiorazione G(L) e L. Se da questo punto non è stata missata alcuna deadline, è possibile non procedere a controllare la parte successiva. Oltre questo punto la G(L) va sotto la L. Se la G è una maggiorazione della g (rossa) e non la missa, allora non è necessario controllare il resto.