- [Scheduling](#scheduling)
  - [Tipologie](#tipologie)
    - [Long Term](#long-term)
    - [Medium Term](#medium-term)
    - [Short Term](#short-term)
  - [Criteri di Selezione dello Scheduling](#criteri-di-selezione-dello-scheduling)
  - [CPU-Bound e I/O Bound](#cpu-bound-e-io-bound)
  - [Semplificazione del Problema](#semplificazione-del-problema)
- [Algoritmi di Scheduling non Real-Time](#algoritmi-di-scheduling-non-real-time)
  - [First In First Out (FIFO o FCFS)](#first-in-first-out-fifo-o-fcfs)
  - [Shortest Job FIrst (SJF)](#shortest-job-first-sjf)
  - [Priority Scheduling](#priority-scheduling)
  - [Round Robin](#round-robin)
    - [Round Robin basato su Priorità](#round-robin-basato-su-priorità)
- [Algoritmi di Scheduling Real Time](#algoritmi-di-scheduling-real-time)
- [Task Periodici e Sporadici](#task-periodici-e-sporadici)
  - [Timeline Scheduling](#timeline-scheduling)
    - [Vantaggi](#vantaggi)
    - [Svantaggi](#svantaggi)
    - [Problema dovuto all'Overload](#problema-dovuto-alloverload)
  - [Priority Scheduling](#priority-scheduling-1)
    - [Verificare la Schedulabilità](#verificare-la-schedulabilità)
      - [Esempio di Schedulabilità](#esempio-di-schedulabilità)
    - [Istante Critico](#istante-critico)
    - [Task Sporadici](#task-sporadici)
      - [Priorità Fissa](#priorità-fissa)
    - [Hyperbolic Bound](#hyperbolic-bound)
- [Priorità Dinamiche](#priorità-dinamiche)
  - [Earliest Deadline First](#earliest-deadline-first)
    - [Vantaggi e Svantaggi](#vantaggi-e-svantaggi)

# Scheduling
Il termine fa riferimento alla selezione di *quale processo o thread selezionare per essere mandato in esecuzione. 
## Tipologie
In generale se ne distiguono di tre tipi:
- Long Term : capire se il sistema rimane sostenibile (schedulabile), quanti task il processore può supportare
- Short Term
- Medium Term

Nel corso affronteremo principalmente gli short, nei quali si deve decidere quale task mandare in esecuzione. I task soggetti a short scheduling si trovano già in stato di pronto.

### Long Term 

### Medium Term
Fa lo swap-in e lo spaw-out. Si decide se il task è gia presente nella memoria RAM.

### Short Term
Funzione di selezione che decide ual'è il prossimo processo (task) da eseguire. La modalità di decisione può essere *preemptive* (il task può essere interrotto in favore di un altro) o *non preemptive*.

## Criteri di Selezione dello Scheduling
Per valutare unoscheduler, in particolare per i sistemi real time è necessario guardare il tempo di risposta. Non a quello generico, ma al *worst case response tipe*. Inoltre si guarda il *throughput*, ovvero il livello di lavoro del processore. Anche la *perfromance* è importante, ma la *predicibilità*, specie in questi tipi di sistema lo è ancora di più: poter prevedere il comportamento di esecuzione rappresenta un grande vantaggio.

## CPU-Bound e I/O Bound
Un processo occupa del tempo nel processore, ma del tempo anche per approvigionare i dati necessari alla sua esecuzione. Questi dati devono essere portati in memoria RAM per essere elaborati dai processori. La memoria è sempre più un collo di bottiglia: in passato non era così, si guardava principalmentela frequenza del processore.

Il programma può avere un tempo di utilizzo della CPU, così come di periferiche di I/O. Un programma viene detto CPU bound se quando si interfacciano verso dispositivi esterni (I/O) non rilasciano la CPU.

**Approfondimento**:
Le prestazioni aumentano in relazione al numero di core nel sistema (non in relazione alla frequenza della CPU!). Sono i *core* che prendono ed elaborano dati. Legge di Moore: piu transistors sullo stesso chip → più capacità computazionale. Per "mangiare" questi dati (data crunching) ho bisogno di dispositivi hardware potenti: le schede video. Con una RAM direttamente sulla GPU c'è un unico bus su cui viaggiano i dati, conferendo un notevole aumento delle prestazioni. La banda rappresenta il modo in cui i dati vengono forniti dalla memoria alla CPU. Negli ultimi anni rimane la stessa. Stesso discorso per la latenza: ci vuole lo stesso tempo per leggere un dato di quanto ci volessero anni fa. Le prestazioni delle CPU sono aumetate notevolmente, tuttavia è la memoria che fa ancora da collo di bottiglia. Se la CPU, in termini di performance nette, migliora un 60% l'anno, la memoria rimane su un 7%. 

Lo schedule è *fattibile* quando, dati un insieme di task, soddisfa tutte le deadline. Un set di task è *schedulabile* se esiste almeno uno scenario in la schedule è fattibie.

- τ insieme di *n* task
- P insieme di *m* processori
- R insieme di *r* risorse

Questi rappresentano gli input del mio sistema. Dati questi tre input bisogna trovare uno schedule fattibile affinchè tutti i task rispettino ciascuno le loro deadline. Il problema dello scheduling è un *problema NP hard*. Si tratta di un problema per cui è estremamente difficile trovare una soluzione polinomiale, pertanto non presentano soluzioni note. Come si dimostra? Si prende un problema già appartenente a questa classe, e tramite un numero di passi polinomiale ti riconduci al problema di partenza (facendo ad esempio delle equivalenze).

## Semplificazione del Problema
In riferimento allo scheduling, si considera *un solo processore*. Inizialmente si partizionano i task sui vari processori: una volta che un task viene assegnato a un processore, non può cambiarlo. Ogni task viene considerato *preemptive*, e non hanno vincoli di precedenza tra loro. Nessun vincolo di tra le risorse (mutex o semafori). Essendo le ultime due semplificazioni molto restrittive, queste non saranno sempre valide in tutti gli scheduler.

La decisione dell'ordine esecuzione può essere fatta *online*, man mano che i task arrivano, oppure *offline*, ad esempio con uno scheduler a priorità fisse dove ciascun task viene accodato in base alla sua priorità. Con il termine priorità *statica* si fa riferimento all'impossibilità della priorità di un task di cambiare nel tempo, viene definita *dinamica* altrimenti, tipica di uno scheduler *deadline based*, dove ogni job appartanente a un task ha una priorità diversa. Uno scheduler *ottimo* trova uno schedule fattibile, mentre uno *best effort* fa il meglio che riesce, senza garantire che sia ottimo, o che riesca a trovare uno schedule fattibile.

# Algoritmi di Scheduling non Real-Time

## First In First Out (FIFO o FCFS)
I task vengono schedulati nell'ordine di arrivo. Questo scheduler *non presenta preemption*: un task non può essere "sorpassato" da uno che arriva dopo. Si tratta di un algoritmo di scheduling *dinamico*, la priorità di un task si basa completamente sul suo arrivo in coda, non è possibile conoscerlo a priori. Poichè non si conosce l'ordine di esecuzione a priori è un algoritmo *online* ed è *best effort*.

## Shortest Job FIrst (SJF)
Viene schedulato per primo il *task con il più piccolo tempo di computazione*. Il vantaggio di questo scheduler è il fatto che *minimizza il tempo di risposta medio*: non è buono per il task realtime, è esclusivamente importante che il task non superi la sua deadline. L'algoritmo può essere *sia preemptive che non preemptive*. L'algoritmo è statico: dipende dal solo tempo di computazione del task, che non cambia. La decisione dell'ordine di esecuzione può essere fattia *sia online che offline*. 

Per dimostrare che questo scheduler minimizza il tempo di risposta si procede con una Dimostrazione per Assurdo. Si prende un algoritmo σ ≠ SJF : affinchè sia diverso deve fare in modo, almeno una volta, di non eseguire il task con il più piccolo tempo di computazione presente nella coda dei task pronti. Minimizzare il tempo di risposta medio coincide con il minimizzare il finishing time medio (somma dei finishing time fratto il numero di task). SJF vince in tutte le simulazioni, pertanto si conferma il migliore nel conseguire l'obiettivo proposto (minimizzare il tempo di risposta).

## Priority Scheduling
Ad ogni task viene assegnata una priorità (solitamente un numero basso sta a rappresentare una priorità più alta). Il task con la priorità maggiore viene selezione per l'esecuzione, qualora due task avessero la stessa priorità vengono scelti mediante FCFS oppure Round Robin. I task generalmente hanno priorità fisse, pertanto hanno priorità fisse anche i task che li compongono. E' uno degli algoritmi di scheduling più utilizzato (anche nei sistemi real time). Il problema di questo scheduling è la *starvation*: task con una bassa priorità non eseguono mai. Una soluzione a questo problema potrebbe essere l'*aging*: più un task aspetta più la sua priorità aumenta, tuttavia così facendo i task non avrebbero più una priorità fissa, e non sarebbe più adatto ai sistemi realtime: nel momento in cui il task esegue potrebbe già essere troppo tardi e potrebbe mancare la sua deadline.


## Round Robin
I task vengono schedulati nell'ordine di arrivo (come in FCFS), ma il sistema presenta il concetto di *quanto di tempo*: ogni task che esegue lo fa per un determinato quanto di tempo. Se un task ha un tempo di esecuzione che super il quanto su di esso viene fatta preemption e ritorna in coda per essere rieseguito.

Definito *n* come il numero di task in un sistema. Per eseguire un task $C_i$ impiego $R_i = n*C_i$. Dove $R_i$ è il *tempo di risposta medio*. E' come se *virtualizzassimo il processore* in relazione al numero di task che abbiamo. Diminuire il quanto di tempo non è sempre una buona soluzione: bisogna considerare anche il tempo di overhead per il cambio di contesto. Se si sceglie un quanto di tempo troppo piccolo si ha solo un tempo di overhead e non si procede mai nell'esecuzione dei task.

### Round Robin basato su Priorità
Se un processo non riesce a finire la sua esecuzione, è possibile spostarlo su un altra coda FIFO con priorità maggiore. In questo modo viene eseguito più spesso ed è più propenso a finire liberando spazio. Vengono così create diverse code ciascuna con priorità differenti. QUesta policy di scheduling tenta di superare i limiti dei processi I/O bound.


# Algoritmi di Scheduling Real Time
I task possono essere scedulati secondo una deadline relativa, con un algoritmo a priorità statica, oppure secondo una *deadline assoluta*, con un *algoritmo a priorità dinamiche*. Consideriamo che tutti i task arrivino simultuaneamente già pronti per l'esecuzione e che la loro priorità sia conosciuta a priori. La *preemption non rappresenta un problema* per queste condizioni iniziali. Gli algoritmi per questo genere di sistemi *minimizzano il ritardo massimo*: non esiste alcun algoritmo che ha una lateness massima più bassa di EED (ha una lateness comunque negativa), e finisce quindi prima della deadline).

# Task Periodici e Sporadici
Di seguito si considerano diversi algoritmi di scheduling per Task Periodici e Sporadici. Non si considerano quei task che vengono eseguiti una sola volta e poi terminano la loro esecuzione. Importante è la grandezza $T$ che è il Periodo.

## Timeline Scheduling
Chiamato anche *cycle executive* o *ciclici scheduling*, o ancora *table driving scheduling*. Viene implementato offline: ancora prima dell'esecuzione del primo task, si decide l'ordine di esecuzione. La loro esecuzione viene rappresentata in forma tabellare, e la tabella viene periodicamente ripetuta. Ha dei pregi e dei difetti: per costruzione, se tutto si comporta a dovere, si ha sempre conoscenza di ciò che succede. Se qualcosa nel sistema cambia, non si ha flessibilità. E' stato uno dei primi scheduler utilizzati, soprattutto in ambito militare.

L'asse del tempo viene divide in *intervalli di uguale lunghezza* chiamati *time slot*. Ogni task viene allocato in uno slot. Se si fa in modo che ogni task non superi mai il suo periodo, allora questo non sfoerà mai la sua deadline. Il *minor cycle* è la granularità con la quale cambio le decisioni di scheduling, mentre il *major cycle* è il ripetersi di un intero ciclo di esecuzione dei diversi task: ci dice ogni quanto tempo si ripete lo scheudule. Il tempo di esecuzione di due job deve essere sempre minore del *minor cycle*. Per un implementazione tipo non è neanche necessario il sistema operativo.

### Vantaggi
Quando tutto è noto a priori funziona molto bene.

### Svantaggi
Scheduler poco configurabile, non si abitua facilmente ad applicazioni che hanno una loro dinamicità. Si dimostra in questi casi uno *scheduler molto poco flessibile*.

### Problema dovuto all'Overload
Se due task eccedono il minor cyclo accade un effetto domino: lo scheduler comincia ad accumulare ritardo. Una soluzione al problema consiste nello *splittare un job in due (o più) diversi job*. Quando ho dei periodi armonici (il periodo di esecuzione di un job è multiplo del precedente) la situazione è più semplice. QUando ciò non accade, sono necessari degli *istanti di sincronizzazione* (interrupt). Ciò comporta un aumento dell'overhead.

## Priority Scheduling
Scheduler più utilizzato in assoluto. Ad ogni task è associata una priorità. RIchiede un sistema operativo con il supporto alle priorità. Come si assegnano queste priorità? Non conviene dare le priorità secondo la loro durata, ma è meglio assegnarla in base *ai periodi dei task*: più piccolo è il periodo maggiore sarà la priorità associata: *rate monotonic*. Questo è stato dimostrato essere l'assegnamento di priorità *ottimale* (non il migliore assoluto! EDF è anche migliore!). Tra tutti gli algoritmi *a priorità fisse*, assegnare la priorità *secondo il rate* è la scelta ottimale: se rate monotonic non ce la fa a schedulare un algoritmo, nessun altro algoritmo a priorità fisse può riuscirci. Anche se la durata di un job è appena più grande, non cambia più di tanto la sua schedulabilità.

[//]: <> (Possibile domanda per l'orale: Disegnare uno scheduler Rate Monotonic - slide 16)

### Verificare la Schedulabilità
Per valutarla è necessario calcolare *l'utilizzazione del processore*: somma delle utilizzazioni di ogni task, ovvero il rapporto tra *execution time* e *periodo*.
$$U_i = \frac{C_i}{T_i}$$

In genere un processore è *occupato ad eseguire un task* 9 volte su 10. Se $U_p > 1$ allora il processore è in *sovraccarico*. A noi interessa quando l'utilizzazione è *minore o uguale a 1*. Tuttavia avere *utilizzazione minore di 1* non è una condizione necessaria alla schedulabilità: è qua che entra in gioco *l'importanza dell'algoritmo*.

Una condizione *necessaria alla schedulabilità*, se non è realizzata, posso dedurre la *non schedulabilità*. Ma se questa è realizzata *non posso dedurre nulla*.

Se una condizione è *sufficiente alla schedulabilità*,
#### Esempio di Schedulabilità 
$$U_{TOT} =  \frac{C_1}{T_1} + \frac{C_2}{T_2} = \frac{2}{4} + \frac{2}{6} $$
$$C_1 = 2, T_1 = 4$$
$$C_1 = 2, T_1 = 6$$
Sotto all'utilizzo, ma non fattibile. La Preemption fa missare il processo $\tau _2$.

Se un task è schedulabile al pelo, allora aumentare uno solo dei due task comporta lo slittamento in avanti del successo (o dei successivi), e a una condizione di *deadline miss*. Quello che si vuole cercare è il *least Uperr Bound*. Se l'utilizzazione del processore è minore dell'upper bound ($Up < U_{lub}$), allora la condizione è sufficiente affinchè il task sia schedulabile con un algoritmo Rate Monotonic. E' stato dimostrato che per un set di n task periodici:
$$ U^{RM}_{lub} = n(2^{1/n}-1)$$

$$\text{per}\; n → \inf \qquad U_{lub}=\ln 2$$

### Istante Critico
[//]: <> (Possibile domanda per l'orale)
Si tratta del worst case della risposta. Se il tempo di risposta è maggiore della deadline non si viene schedulati. Si vuole quindi trovare la situazione di arrivo che massimizza il tempo di risposta. L'*arrivo sincrono* di tutti i task corrisponde *al tempo peggiore di risposta*. Per ogni task, il tempo di risposta massimo ad ogni task è quello degli altri task a priorità più alta di lui: un task con priorità più bassa non viene neanche considerato.

### Task Sporadici
Alternativa più comoda ai task periodici. $T_i$ diventa il *minimo tempo di interarrivo*. Consiste nel *minimo tempo che deve passare prima dell'arrivo del prossimo task*. Ciascun job $\tau _{ik}$ deve essere attivato con un ritardo $r_{ik} = r_{i(k-1)} + T_i$.

#### Priorità Fissa
Anche in questo caso: *il caso peggiore per i task sporadici è lo stesso per i periodici*. I task arrivano esattamente periodici in un istante $T_0$. Il caso sporadico si rifà a quello periodico. Ogni task viene rilasciato il prima possibile. Tutti i risultati ottenuti per i task periodici valgono anche per i periodici, compreso il calcolo di $U^{RM}_{lub}$.

### Hyperbolic Bound
Si vuole cercare di esplorare la zona da $1 < U < U_{lub}$, per massimizzare l'utilizzo del processore. Questo *hyperbolic bound* consiste nel fare la produttoria dell'utilizzazione di tutti i task *più 1*: se il risultato è minore di due allora il task set è *schedulabile*. E' un test sufficiente, ma non necessario. Migliora rispetto al precedente (aumenta la regione di discriminazione), ma non in modo troppo significativo.

I problemi che calcolano HB e LL hanno una *complessità lineare*.

# Priorità Dinamiche

## Earliest Deadline First
Fintanto che $U ⩽ 1$ con EDF l'esecuzione riesce sempre. E' ottimale per tutti gli algoritmi di scheduling. Permette di riempire compeltamente il processore. Si assumono sempre *deadline uguale al periodo* e *accesso alle risorse condiviso*. Con EDF tutti rispettano le proprie deadline. Quelli che prima con Rate Monotonic davano *deadline miss* ora riescono a eseguire.
[//]: <> (Possibile domanda per l'orale -> dimostrazione)

Per EDF il *least upper bound è uguale a 1*. 
$$U_{upb} = 1$$

Con EDF in generale si hanno *meno cambi di contesto*. A priorità fisse, se arriva un task ad alta priorità c'è *sempre preemption*. A priorità dinamiche l'algoritmo *concede di più*.

### Vantaggi e Svantaggi
Task Priority è prevedibile: un task comincia e finisce sempre nello stesso istante. Si ha una maggiore periodicità nei task ad alta priorità (sono come orologi). EDF è più variabile, finchè ha spazio prima della deadline se lo prende per ottimizzare l'utilizzo del processore. Questo comporta un jitter sempre variabile. EDF rimane comunque l'algoritmo più efficiente.

In caso di overload, RM non cambia il comportamento, cosa che accade invece per EDF. Esistono tuttavia dei modi per ridurre questi comportamenti indesiderati di EDF, attraverso i *real time server*.

Fino a questo momento si assumeva di avere una *deadline uguale al periodo*.