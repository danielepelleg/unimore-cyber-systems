- [Scheduling](#scheduling)
  - [Tipologie](#tipologie)
    - [Long Term](#long-term)
    - [Medium Term](#medium-term)
    - [Short Term](#short-term)
  - [Criteri di Selezione dello Scheduling](#criteri-di-selezione-dello-scheduling)
  - [CPU-Bound e I/O Bound](#cpu-bound-e-io-bound)
  - [Semplificazione del Problema](#semplificazione-del-problema)
- [Algoritmi di Scheduling non Real-Time](#algoritmi-di-scheduling-non-real-time)
  - [First In First Out (FIFO o FCFS)](#first-in-first-out-fifo-o-fcfs)
  - [Shortest Job FIrst (SJF)](#shortest-job-first-sjf)
  - [Priority Scheduling](#priority-scheduling)
  - [Round Robin](#round-robin)
    - [Round Robin basato su Priorità](#round-robin-basato-su-priorità)
- [Algoritmi di Scheduling Real Time](#algoritmi-di-scheduling-real-time)
- [Task Periodici e Sporadici](#task-periodici-e-sporadici)
  - [Timeline Scheduling](#timeline-scheduling)

# Scheduling
Il termine fa riferimento alla selezione di *quale processo o thread selezionare per essere mandato in esecuzione. 
## Tipologie
In generale se ne distiguono di tre tipi:
- Long Term : capire se il sistema rimane sostenibile (schedulabile), quanti task il processore può supportare
- Short Term
- Medium Term

Nel corso affronteremo principalmente gli short, nei quali si deve decidere quale task mandare in esecuzione. I task soggetti a short scheduling si trovano già in stato di pronto.

### Long Term 

### Medium Term
Fa lo swap-in e lo spaw-out. Si decide se il task è gia presente nella memoria RAM.

### Short Term
Funzione di selezione che decide ual'è il prossimo processo (task) da eseguire. La modalità di decisione può essere *preemptive* (il task può essere interrotto in favore di un altro) o *non preemptive*.

## Criteri di Selezione dello Scheduling
Per valutare unoscheduler, in particolare per i sistemi real time è necessario guardare il tempo di risposta. Non a quello generico, ma al *worst case response tipe*. Inoltre si guarda il *throughput*, ovvero il livello di lavoro del processore. Anche la *perfromance* è importante, ma la *predicibilità*, specie in questi tipi di sistema lo è ancora di più: poter prevedere il comportamento di esecuzione rappresenta un grande vantaggio.

## CPU-Bound e I/O Bound
Un processo occupa del tempo nel processore, ma del tempo anche per approvigionare i dati necessari alla sua esecuzione. Questi dati devono essere portati in memoria RAM per essere elaborati dai processori. La memoria è sempre più un collo di bottiglia: in passato non era così, si guardava principalmentela frequenza del processore.

Il programma può avere un tempo di utilizzo della CPU, così come di periferiche di I/O. Un programma viene detto CPU bound se quando si interfacciano verso dispositivi esterni (I/O) non rilasciano la CPU.

**Approfondimento**:
Le prestazioni aumentano in relazione al numero di core nel sistema (non in relazione alla frequenza della CPU!). Sono i *core* che prendono ed elaborano dati. Legge di Moore: piu transistors sullo stesso chip → più capacità computazionale. Per "mangiare" questi dati (data crunching) ho bisogno di dispositivi hardware potenti: le schede video. Con una RAM direttamente sulla GPU c'è un unico bus su cui viaggiano i dati, conferendo un notevole aumento delle prestazioni. La banda rappresenta il modo in cui i dati vengono forniti dalla memoria alla CPU. Negli ultimi anni rimane la stessa. Stesso discorso per la latenza: ci vuole lo stesso tempo per leggere un dato di quanto ci volessero anni fa. Le prestazioni delle CPU sono aumetate notevolmente, tuttavia è la memoria che fa ancora da collo di bottiglia. Se la CPU, in termini di performance nette, migliora un 60% l'anno, la memoria rimane su un 7%. 

Lo schedule è *fattibile* quando, dati un insieme di task, soddisfa tutte le deadline. Un set di task è *schedulabile* se esiste almeno uno scenario in la schedule è fattibie.

- τ insieme di *n* task
- P insieme di *m* processori
- R insieme di *r* risorse

Questi rappresentano gli input del mio sistema. Dati questi tre input bisogna trovare uno schedule fattibile affinchè tutti i task rispettino ciascuno le loro deadline. Il problema dello scheduling è un *problema NP hard*. Si tratta di un problema per cui è estremamente difficile trovare una soluzione polinomiale, pertanto non presentano soluzioni note. Come si dimostra? Si prende un problema già appartenente a questa classe, e tramite un numero di passi polinomiale ti riconduci al problema di partenza (facendo ad esempio delle equivalenze).

## Semplificazione del Problema
In riferimento allo scheduling, si considera *un solo processore*. Inizialmente si partizionano i task sui vari processori: una volta che un task viene assegnato a un processore, non può cambiarlo. Ogni task viene considerato *preemptive*, e non hanno vincoli di precedenza tra loro. Nessun vincolo di tra le risorse (mutex o semafori). Essendo le ultime due semplificazioni molto restrittive, queste non saranno sempre valide in tutti gli scheduler.

La decisione dell'ordine esecuzione può essere fatta *online*, man mano che i task arrivano, oppure *offline*, ad esempio con uno scheduler a priorità fisse dove ciascun task viene accodato in base alla sua priorità. Con il termine priorità *statica* si fa riferimento all'impossibilità della priorità di un task di cambiare nel tempo, viene definita *dinamica* altrimenti, tipica di uno scheduler *deadline based*, dove ogni job appartanente a un task ha una priorità diversa. Uno scheduler *ottimo* trova uno schedule fattibile, mentre uno *best effort* fa il meglio che riesce, senza garantire che sia ottimo, o che riesca a trovare uno schedule fattibile.

# Algoritmi di Scheduling non Real-Time

## First In First Out (FIFO o FCFS)
I task vengono schedulati nell'ordine di arrivo. Questo scheduler *non presenta preemption*: un task non può essere "sorpassato" da uno che arriva dopo. Si tratta di un algoritmo di scheduling *dinamico*, la priorità di un task si basa completamente sul suo arrivo in coda, non è possibile conoscerlo a priori. Poichè non si conosce l'ordine di esecuzione a priori è un algoritmo *online* ed è *best effort*.

## Shortest Job FIrst (SJF)
Viene schedulato per primo il *task con il più piccolo tempo di computazione*. Il vantaggio di questo scheduler è il fatto che *minimizza il tempo di risposta medio*: non è buono per il task realtime, è esclusivamente importante che il task non superi la sua deadline. L'algoritmo può essere *sia preemptive che non preemptive*. L'algoritmo è statico: dipende dal solo tempo di computazione del task, che non cambia. La decisione dell'ordine di esecuzione può essere fattia *sia online che offline*. 

Per dimostrare che questo scheduler minimizza il tempo di risposta si procede con una Dimostrazione per Assurdo. Si prende un algoritmo σ ≠ SJF : affinchè sia diverso deve fare in modo, almeno una volta, di non eseguire il task con il più piccolo tempo di computazione presente nella coda dei task pronti. Minimizzare il tempo di risposta medio coincide con il minimizzare il finishing time medio (somma dei finishing time fratto il numero di task). SJF vince in tutte le simulazioni, pertanto si conferma il migliore nel conseguire l'obiettivo proposto (minimizzare il tempo di risposta).

## Priority Scheduling
Ad ogni task viene assegnata una priorità (solitamente un numero basso sta a rappresentare una priorità più alta). Il task con la priorità maggiore viene selezione per l'esecuzione, qualora due task avessero la stessa priorità vengono scelti mediante FCFS oppure Round Robin. I task generalmente hanno priorità fisse, pertanto hanno priorità fisse anche i task che li compongono. E' uno degli algoritmi di scheduling più utilizzato (anche nei sistemi real time). Il problema di questo scheduling è la *starvation*: task con una bassa priorità non eseguono mai. Una soluzione a questo problema potrebbe essere l'*aging*: più un task aspetta più la sua priorità aumenta, tuttavia così facendo i task non avrebbero più una priorità fissa, e non sarebbe più adatto ai sistemi realtime: nel momento in cui il task esegue potrebbe già essere troppo tardi e potrebbe mancare la sua deadline.


## Round Robin
I task vengono schedulati nell'ordine di arrivo (come in FCFS), ma il sistema presenta il concetto di *quanto di tempo*: ogni task che esegue lo fa per un determinato quanto di tempo. Se un task ha un tempo di esecuzione che super il quanto su di esso viene fatta preemption e ritorna in coda per essere rieseguito.

Definito *n* come il numero di task in un sistema. Per eseguire un task $C_i$ impiego $R_i = n*C_i$. Dove $R_i$ è il *tempo di risposta medio*. E' come se *virtualizzassimo il processore* in relazione al numero di task che abbiamo. Diminuire il quanto di tempo non è sempre una buona soluzione: bisogna considerare anche il tempo di overhead per il cambio di contesto. Se si sceglie un quanto di tempo troppo piccolo si ha solo un tempo di overhead e non si procede mai nell'esecuzione dei task.

### Round Robin basato su Priorità
Se un processo non riesce a finire la sua esecuzione, è possibile spostarlo su un altra coda FIFO con priorità maggiore. In questo modo viene eseguito più spesso ed è più propenso a finire liberando spazio. Vengono così create diverse code ciascuna con priorità differenti. QUesta policy di scheduling tenta di superare i limiti dei processi I/O bound.


# Algoritmi di Scheduling Real Time
I task possono essere scedulati secondo una deadline relativa, con un algoritmo a priorità statica, oppure secondo una *deadline assoluta*, con un *algoritmo a priorità dinamiche*. Consideriamo che tutti i task arrivino simultuaneamente già pronti per l'esecuzione e che la loro priorità sia conosciuta a priori. La *preemption non rappresenta un problema* per queste condizioni iniziali. Gli algoritmi per questo genere di sistemi *minimizzano il ritardo massimo*: non esiste alcun algoritmo che ha una lateness massima più bassa di EED (ha una lateness comunque negativa), e finisce quindi prima della deadline).

# Task Periodici e Sporadici
Di seguito si considerano diversi algoritmi di scheduling per Task Periodici e Sporadici. Non si considerano quei task che vengono eseguiti una sola volta e poi terminano la loro esecuzione.

## Timeline Scheduling
Chiamato anche *cycle execuive*. Viene implementato offline: ancora prima dell'esecuzione del primo task, si decide l'ordine di esecuzione. La loro esecuzione viene rappresentata in forma tabellare. Ha dei pregi e dei difetti: per costruzione, se tutto si comporta a dovere, si ha sempre conoscenza di ciò che succede. Se qualcosa nel sistema cambia, non si ha flessibilità. E' stato uno dei primi scheduler utilizzati, soprattutto in ambito militare.

L'asse del tempo viene divide in *intervalli di uguale lunghezza* chiamati *time slot*. Ogni task viene allocato in uno slot. Se s fa in modo che ogni task non superi mai il suo periodo, allora questo non sfoerà mai la sua  deadline. Il *minor cycle* è la granularità con la quale cambio le decisioni di scheduling, mentre il *major cycle* è il ripetersi di un intero ciclo di esecuzione dei diversi task.