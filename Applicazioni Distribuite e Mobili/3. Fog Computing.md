- [Performance Evaluation](#performance-evaluation)
  - [Approcci](#approcci)
    - [Differenze](#differenze)
  - [Parametri di Performance](#parametri-di-performance)
    - [Capacità di Pianificazione](#capacità-di-pianificazione)
    - [Elasticità](#elasticità)
  - [Tipologie di Test](#tipologie-di-test)
    - [Benchmark](#benchmark)
      - [SPEC](#spec)
        - [SPEC Web](#spec-web)
        - [SPEC Cloud](#spec-cloud)
      - [YCSB](#ycsb)
      - [PerfKit](#perfkit)
  - [Modello Matematico per l'Analisi del Sistema](#modello-matematico-per-lanalisi-del-sistema)
    - [Modello di rete](#modello-di-rete)
  - [Legge dell'Utilizzazione](#legge-dellutilizzazione)

# Performance Evaluation
## Approcci
L'utilizzo di strumenti più astratti si presta bene per scenari ampi, dove può essere necessario esplorare un numero più ampio di soluzioni.

### Differenze
Non c'è un approccio giusto. Quello da utilizzare dipende dal tipo di risposta che è necessario trovare. E' sempre bene comunque lavorare su un *modello* piuttosto che sul sistema reale. Quando si utilizza un modello è bene che questo *non sia troppo approssimativo* per valutare al meglio le soluzioni. Il problema dell'accuratezza rispetto alla flessibilità è qualcosa di noto.

Sbagliare il deployment del proprio sistema vuol dire incorrere in *spese superflue*.

## Parametri di Performance
- **Tempi di Risposta** : tempo che intercorre tra quando si invia una richiesta e quando si riceve l'ultimo byte. Una parte del ritardo è dovuto anche alla rete.
- **Throughput** : numero di richieste che è possibile soddisfare in una determinata unità di tempo
- **Error Rate** : quante richieste non vengono soddisfatte a causa dell'overload. 
 
Per valutare le performance, per ciascuno dei parametri precedentemente citati, si visualizzano le *curve di carico del sistema*. Nella zona verde è tutto ok, la zona gialla evidenzia quando si sta entrando in saturazione, mentre la rossa quella di threshold.

### Capacità di Pianificazione
Il carico di lavoro cambia nel tempo. Ciò che funziona bene oggi non è detto funzioni domani. Il carico può essere soggetto a variazioni (esempio del black friday sui principali store online). Il *Capacity Planning* consiste nel capire *come scalare il sistema* in modo da spostare la curva di carico in maniera corretta, senza entrare nella zona di soglia.

### Elasticità
L'elasticità è una caratteristica chiave del *cloud computing*, che permette di acquistare *potenza computazionale* aggiuntiva in caso di bisogno. Per capire però le quantità di cui si ha *veramente bisogno* è comunque necessario *comprendere le performance del proprio sistema*. Senza queste operazioni preliminari di analisi le operazioni possono diventare di difficile implementazione oltre che costose.

## Tipologie di Test
Prima di fare qualsiasi cosa bisogna stabilire l'*obiettivo dell'analisi* che si vuole fare:
- **Test Funzionale** : si analizza se il sistema si comporta come dovrebbe
- **Activity Testing** : si testa il sistema con un carico di lavoro realistico. Un possibile modo per fare activity testing è quello di fare *un deployment controllato*.
- **Endurance Testing** : si testa la capacità del sistema di scalare. Si testa lo scenario che si può immaginare durante un *momento di picco* (come ad esempio un determinato giorno dell'anno o una fascia oraria della giornata). Quando si fanno questo tipo di analisi *non si cerca di rompere il sistema*: non si guarda il sistema morire.
- **Stress Testing** : si testano *i limiti del sistema*, analizzando fino a dove è possibile arrivare senza incorrere a dei problemi. In questo caso il caso viene aumentato in maniera controllata fino a capire quanto è possibile spingersi prima che *il sistema si rompa*. Una volta raggiunto questo punto, si cerca di trovare *l'anello debole della catena* che causa la *rottura del sistema*.
- **Benchmarking** : si analizzano le perfomance del sistema, confrontandole ad esempio con altre architettura simili. Si cercano uno o più workload definiti in maniera chiara e standardizzati.

### Benchmark
Il concetto di benchmark risale alla *valutazione di sistemi hardware*. 
- **Synthetic Benchmark** : utilizzati per confrontare tra loro processori differenti.

I principali sponsor dei benchmark sono enti che hanno collaborazioni con i produttori di chip. Alcuni dei produttori non mirano a fare la CPU buona in generale, ma ne massimizzano i risultati ottenuti sui benchmark.

#### SPEC
##### SPEC Web
##### SPEC Cloud
#### YCSB
Acronimo di *Yahoo Cloud Service Benchmark*. Viene cambiato il numero di nodi per osservare come cambia il throughput.

#### PerfKit
Strumento di Google che valuta soluzioni cloud diverse. Supporta il deployment sia su cloud google che su sistemi *open cloud* basati su open stack oltre a diverse soluzioni di workload. Dal workload otteniamo anche i *parametri di generazione del traffico*.

## Modello Matematico per l'Analisi del Sistema
Elementi come la rete, backend, forntend e nodi intermedi comportano un *contributo* al tempo di risposta. QUesto può essere diviso in *tempo speso a fare calcolo*, *tempo di storage* (i tempi di storage per dispositivi non ssd possono essere dell'ordine del *ms* e dare un contributo importanti). Il modello matematico più comodo deriva dalla *teoria delle reti di code*.

### Modello di rete
I pacchetti che arrivano sulla rete vengono accodati sul buffer, e rimangono in coda fintanto che non si libera il canale trasmissivo (*risorsa*).

## Legge dell'Utilizzazione
Il sistema viene analizzato per un periodo $\tau$ e si suppone che abbia soddistatto un numero di richieste $C_i$. Il throughput $X_i = \frac{C_i}{τ}$

[//]: # (Possibile Dimostrazione: Pollaczek-Khinchin Formula slide 77)